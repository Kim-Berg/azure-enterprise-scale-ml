import os
import joblib
import sys
import numpy as np
import pandas as pd
import json
import logging

from azureml.automl.core.shared import logging_utilities, log_server

from inference_schema.schema_decorators import input_schema, output_schema
from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType
from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType

output_sample = np.array([0])

# TODO 4 YOU: If you want to use the decorator, @input_schema, You need to speficy YOUR SCHEMA here
#input_sample = pd.DataFrame({"Pclass": pd.Series([0], dtype="int64"), "Name": pd.Series(["example_value"], dtype="object"), "Sex": pd.Series(["example_value"], dtype="object"), "Age": pd.Series([0.0], dtype="float64"), "Siblings/Spouses Aboard": pd.Series([0], dtype="int64"), "Parents/Children Aboard": pd.Series([0], dtype="int64"), "Fare": pd.Series([0.0], dtype="float64")})
input_sample = pd.DataFrame({"AGE": pd.Series([0.0], dtype="float64"), "SEX": pd.Series([0.0], dtype="float64"), "BMI": pd.Series([0.0], dtype="float64"), "BP": pd.Series([0.0], dtype="float64"), "S1": pd.Series([0.0], dtype="float64"), "S2": pd.Series([0.0], dtype="float64"), "S3": pd.Series([0.0], dtype="float64"), "S4": pd.Series([0.0], dtype="float64"), "S5": pd.Series([0.0], dtype="float64"), "S6": pd.Series([0.0], dtype="float64")})

def init():
    global model, info_message
    info_message = ""
    model = None
    model_name = 'model.pkl' # expected to use default name, same as, IESMLController.get_known_model_name_pkl()
    model_name_custom = '11_diabetes_model_reg'
    model_path_with_version = os.getenv('AZUREML_MODEL_DIR') # "/var/azureml-app/azureml-models/11_diabetes_model_reg/43/"
    
    #print("This file is copied to the Pipeline run train steps 'outputs/your_scoring_file_v_1_0_0.py', by ESML")
    #print("-TODO 4 YOU: Since not using AutoML, which autogenerated the scoring files such as this file - you need to implement this method: init()")
    #print("-Note: This file is only needed, for AKS online deploymet. Not needed for Azure ML pipeline batch scoring")
     
    try:
        info_message = info_message + "01:Trying to deserialize model with name with {}. ".format(model_name)
        model_path = os.path.join(model_path_with_version, model_name)
        model = joblib.load(model_path)
        info_message = info_message + "01=SUCCESS: {}".format(model_path)
        print (info_message)
        logging.info(info_message)
    except Exception as e:
        info_message = info_message + "02: Could not deserialize model with model_name '{}' (usually 'model.pkl'), now using custom name: '{}'. Error: ".format(model_name,model_name_custom, str(e))
        
        path = os.path.normpath(model_path)
        path_split = path.split(os.sep)
        model_name_from_path = path_split[-3]
        model_version_from_path = path_split[-2]
        
        info_message = info_message + "02: Could not deserialize model with model_name '{}' (usually 'model.pkl'), now using 'model_name_from_path': '{}'. Error: {}".format(model_name,model_name_from_path, str(e))
        model_name = model_name_from_path
        try:
            model_path = os.path.join(model_path_with_version,'outputs', model_name,'model.pkl')  # /var/azureml-app/azureml-models/11_diabetes_model_reg/43/11_diabetes_model_reg/model.pkl
            model = joblib.load(model_path)
            info_message = info_message + "02:SUCCESS: {}".format(model_path)
            logging.info(info_message)
        except Exception as e2:
            try: # AutoML 2023 way
                info_message = info_message + "03: Could not deserialize model with PATH::: {} Error:{}".format(model_path,str(e2))
                model_path = os.path.join(model_path_with_version,'outputs/featurization/pipeline/','model.pkl')
                
                # REMOVE? ->>>
                log_info = 'model_name: {} path_split[-3] and model_version:'.format(model_name_from_path, model_version_from_path)
                log_server.update_custom_dimensions({'model_name': model_name_from_path, 'model_version': model_version_from_path})
                logging.info(log_info)
                # REMOVE? <<<--
                p1 = model_path_with_version+"/outputs/model.pkl" # TODO: test again

                # 03b)
                path_of_the_directory= model_path_with_version
                info_message = info_message + " 03b: Now printing paths in DIR: {}:".format(path_of_the_directory)

                str_files_1 = ""
                for filename in os.listdir(path_of_the_directory):
                    f = os.path.join(path_of_the_directory,filename)
                    if os.path.isfile(f): 
                        str_files_1 = str_files_1 + f
                    str_files_1 = str_files_1 + " - " + filename

                info_message = info_message + str_files_1

                 # 03c)
                
                # 03d) Walk! 
                path_of_the_directory= '/var/azureml-app/azureml-models/{}/'.format(model_name_from_path)
                info_message = info_message + " 03d: Now printing ALL paths in DIR: {}:".format(path_of_the_directory)
                str_files_1 = ""
                for path, subdirs, files in os.walk(path_of_the_directory):
                    for name in files:
                        n1 = os.path.join(path, name)
                        str_files_1 = str_files_1 + " : " + str(n1)
                
                # 03z)
                directory_list = os.listdir()
                all_curr = ""
                all_curr = ','.join(directory_list)
                info_message = info_message + " 03z) Files in current DIR: " + all_curr
                
                # 03)
                info_message = info_message + " 03: now trying P1: path: {} ".format(p1)
                model = joblib.load(p1)
                info_message = info_message + "03:SUCCESS"
                logging.info(info_message)
            except Exception as e3:
                info_message = info_message + str(e) + str(e2) +str(e3)
                print (info_message)
                logging.error(info_message)

@input_schema('data', PandasParameterType(input_sample))
@output_schema(NumpyParameterType(output_sample))
def run(data):
    #print("This file is copied to the Pipeline run train steps 'outputs/your_scoring_file_v_1_0_0.py', by ESML")
    #print("-TODO 4 YOU: Since not using AutoML, which autogenerated the scoring files such as this file - you need to implement this method: run(data)")
    #print("-Note: This file is only needed, for AKS online deploymet. Not needed for Azure ML pipeline batch scoring")
    info_message_init = ""

    if (model is None):
        print (info_message)
        logging.error(info_message)
        return json.dumps({"error": info_message})
    else:
        try:
            probability_y = None
            result = None
            try:
                if isinstance(data, pd.DataFrame):
                    result = model.predict(data) # as expected if having @input_schema
                    if (model is not None and (hasattr(model, 'predict_proba') == False)):
                        info_message_init = info_message_init + "03:Has @input_schema and data is DataFrame. has_predict_proba=False"
                        result = result
                else: # if not @input_schema, you need to handle this
                    d1 = convert_to_list(data)
                    pd_data = None
                    try:
                        pd_data = pd.DataFrame(d1)
                    except Exception as e4:
                        if(ValueError is type(e4)):
                            pd_data = pd.DataFrame(d1,index=[0])

                    result = model.predict(pd_data)
                    if (model is not None and (hasattr(model, 'predict_proba') == False)):
                        result = result[0]

            except Exception as e8:
                # if you don't have an @input_schema and pass a list - you need to convert to numpy array and reshape
                reshape1 = "03: model.predict(data) failed (please add @input_schema to avoid this) - now trying to Reshape 1,-1 - ESML end. Error:" + str(e8)
                info_message_init = info_message_init + reshape1
                print(info_message_init)
                logging.error(info_message_init)

                # TODO 4 YOU - below is just an example - you need to handle this, in the TRY block prefferebly                
                d1 = convert_to_list(data)
                narr = np.array(d1).reshape(1, -1)
                pd_data = pd.DataFrame(narr)
                result = model.predict(pd_data)
                result = result[0]

            # ADD predict_proba - IF model supports this....need to handle that case
            if model is not None and hasattr(model, 'predict_proba') \
                    and model.predict_proba is not None and data is not None:
                try:
                    probability_y = model.predict_proba(data)
                except Exception as ex:
                    raise ValueError("Model does not support predict_proba method for given dataset \
                        type, inner error: {}".format(ex))
                try:
                    probability_y = convert_to_list(probability_y[:, 1]) # Change to "probability_y" if both [negative_percentage, positive_percentage]
                except Exception as ex:
                    raise ValueError("Model predict_proba output of unsupported type, inner error: {}".format(ex))
            # predict_proba END

            return json.dumps({'result': result.tolist(), 'probability': probability_y,'esml_info': info_message})
        except Exception as e:
            result = str(e) + info_message + info_message_init
            logging.error(result)
            return json.dumps({"error": result})

from scipy.sparse import issparse
def convert_to_list(df_series_or_ndarray):
    if issparse(df_series_or_ndarray):
        return df_series_or_ndarray.toarray().tolist()
    if (isinstance(df_series_or_ndarray, pd.DataFrame)):
        return df_series_or_ndarray.values.tolist()
    if (isinstance(df_series_or_ndarray, pd.Series)):
        return df_series_or_ndarray.values.tolist()
    if (isinstance(df_series_or_ndarray, np.ndarray)):
        return df_series_or_ndarray.tolist()
    return df_series_or_ndarray