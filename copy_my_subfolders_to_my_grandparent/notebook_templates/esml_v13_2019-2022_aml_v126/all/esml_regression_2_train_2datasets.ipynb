{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESML - accelerator: Quick DEMO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import repackage\n",
    "repackage.add(\"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "\n",
    "p = ESMLProject() # Will search in ROOT for your copied SETTINGS folder '../../../settings', you should copy template settings from '../settings'\n",
    "p.active_model = 11\n",
    "p.inference_mode = False\n",
    "p.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregister_all_datasets=False\n",
    "if(unregister_all_datasets):\n",
    "    p.unregister_all_datasets(p.ws) # For DEMO purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "ws = Workspace.get(name = p.workspace_name,subscription_id = p.subscription_id,resource_group = p.resource_group,auth=auth)\n",
    "ws.write_config(path=\".\", file_name=\"../../ws_config.json\")\n",
    "\n",
    "ws = Workspace.from_config(\"../ws_config.json\") # Reads config.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) ESML will Automap and Autoregister Azure ML Datasets - IN, SILVER, BRONZE, GOLD\n",
    "- `Automap` and `Autoregister` Azure ML Datasets as: `IN, SILVER, BRONZE, GOLD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws, config_name = p.authenticate_workspace_and_write_config()\n",
    "ws = p.get_workspace_from_config()\n",
    "ws.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Are we in R&D state (no dataset versioning) = {}\".format(p.rnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = p.init(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) IN->`BRONZE->SILVER`->Gold\n",
    "- Create dataset from PANDAS - Save to SILVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "ds = p.DatasetByName(\"ds01_diabetes\")\n",
    "df = ds.Bronze.to_pandas_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) BRONZE-SILVER (EDIT rows & SAVE)\n",
    "- Test change rows, same structure = new version (and new file added)\n",
    "- Note: not earlier files in folder are removed. They are needed for other \"versions\". \n",
    "- Expected: For 3 files: New version, 997 rows: 2 older files=627 + 1 new file=370\n",
    "- Expected (if we delete OLD files): New version, with less rows. 370 instead of 997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df.AGE > 0.015]\n",
    "print(df.shape[0], df_filtered.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a) Save `SILVER` ds01_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_silver = p.save_silver(p.DatasetByName(\"ds01_diabetes\"),df_filtered)\n",
    "aml_silver.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARE `BRONZE vs SILVER`\n",
    "- Compare and validate the feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds01 = p.DatasetByName(\"ds01_diabetes\")\n",
    "bronze_rows = ds01.Bronze.to_pandas_dataframe().shape[0]\n",
    "silver_rows = ds01.Silver.to_pandas_dataframe().shape[0]\n",
    "\n",
    "print(\"Bronze: {}\".format(bronze_rows)) # Expected 442 rows\n",
    "print(\"Silver: {}\".format(silver_rows)) # Expected 185 rows (filtered)\n",
    "\n",
    "assert bronze_rows == 442,\"BRONZE Should have 442 rows to start with, but is {}\".format(bronze_rows)\n",
    "assert silver_rows == 185,\"SILVER should have 185 after filtering, but is {}\".format(silver_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Save  `BRONZE â†’  SILVER` ds02_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edited = p.DatasetByName(\"ds02_other\").Silver.to_pandas_dataframe()\n",
    "ds02_silver = p.save_silver(p.DatasetByName(\"ds02_other\"),df_edited)\n",
    "ds02_silver.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c) Merge all `SILVERS -> then save GOLD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = ds01.Silver.to_pandas_dataframe()\n",
    "df_02 = ds02_silver.to_pandas_dataframe()\n",
    "df_gold1_join = df_01.join(df_02) # left join -> NULL on df_02\n",
    "print(\"Diabetes shape: \", df_01.shape)\n",
    "print(df_gold1_join.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save `GOLD` v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.rnd=False # Allow versioning on DATASETS, to have lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gold_v1 = p.save_gold(df_gold1_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c) Ops! \"faulty\" GOLD - too many features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.Gold.to_pandas_dataframe().shape) # 19 features...I want 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Are we in RnD phase? Or do we have 'versioning on datasets=ON'\")\n",
    "print(\"RnD phase = {}\".format(p.rnd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save `GOLD` v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just go with features from ds01\n",
    "ds_gold_v1 = p.save_gold(df_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get `GOLD` by version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_1 = p.get_gold_version(1)\n",
    "gold_1.to_pandas_dataframe().shape # (185, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_2 = p.get_gold_version(2)\n",
    "gold_2.to_pandas_dataframe().shape # (185, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.Gold.to_pandas_dataframe().shape # Latest version (185, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01_filtered = df_01[df_01.AGE > 0.03807]\n",
    "ds_gold_v1 = p.save_gold(df_01_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_2 = p.get_gold_version(3) # sliced, from latest version\n",
    "gold_2.to_pandas_dataframe().shape # (113, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN - `AutoMLFactory + ComputeFactory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselayer_azure_ml import AutoMLFactory, ComputeFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.dev_test_prod = \"test\"\n",
    "print(\"what environment are we targeting? =  {}\".format(p.dev_test_prod)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_performance_config = p.get_automl_performance_config()\n",
    "automl_performance_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.dev_test_prod = \"dev\"\n",
    "automl_performance_config = p.get_automl_performance_config()\n",
    "automl_performance_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get `COMPUTE` for current `ENVIRONMENT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_compute = p.get_training_aml_compute(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TRAIN` model -> See other notebook `esml_howto_2_train.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from baselayer_azure_ml import azure_metric_regression\n",
    "\n",
    "label = p.active_model[\"label\"]\n",
    "train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6,label) # Auto-registerin AZURE (M03_GOLD_TRAIN | M03_GOLD_VALIDATE | M03_GOLD_TEST) # Alt: train,testv= p.Gold.random_split(percentage=0.8, seed=23)\n",
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                             primary_metric = azure_metric_regression.MAE,\n",
    "                             compute_target = aml_compute,\n",
    "                             training_data = p.GoldTrain, # is 'train_6' pandas dataframe, but as an Azure ML Dataset\n",
    "                             label_column_name = label,\n",
    "                             experiment_exit_score = '0.308', # DEMO purpose\n",
    "                             **automl_performance_config\n",
    "                            )\n",
    "\n",
    "via_pipeline = False\n",
    "best_run, fitted_model, experiment = AutoMLFactory(p).train_pipeline(automl_config) if via_pipeline else AutoMLFactory(p).train_as_run(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESML - accelerator\n",
    "\n",
    "## PROJECT + DATA CONCEPTS + ENTERPRISE Datalake Design + DEV->PROD MLOps\n",
    "- `1)ESML Project`: The ONLY thing you need to remember is your `Project number` (and `BRONZE, SILVER, GOLD` concept )\n",
    "    - ProjectNo=4 have a list of all your datasets as ESMLDatasets. (Well you need to provide names for them also: \"mydata01\", \"mydata02\" - but thats it)\n",
    "- `2)Lakedesign & Roles`: Bronze, silver, gold + IN and date folders\n",
    "    - Benefits: Physical datalake design!  onnected to Azure ML Workspace, with autoregistration of `Azure ML Datasets`\n",
    "    - `Role 1`: `Data ingestion team` only need to care about 1 thing - onboard data to `IN-folder`, in .CSV format\n",
    "        - `Auto parquet-conversion` from `IN` folder (.CSV) to `OUT`/BRONZE/bronze.PARQUET \n",
    "    - `Role 2`: `Data scientists` only need to care about 3 things (R/W): `BRONZE, SILVER, GOLD` datasets, all in .PARQUET format\n",
    "    - How? The ESML project will `Automap` and `Autoregister` Azure ML Datasets - `IN, SILVER, BRONZE, GOLD`\n",
    "- `2a) R&D  VS Production phase`: \"Latest data\" VS versioning on Datasets and datefolders  \n",
    "    - Benefits \"R&D mode\": Faster RnD phase to onboard and refresh data easy. Also fast \"flip-switch\" to production\n",
    "    - How? `ESMLDataset is context self aware` - knows when it is used in TRAIN or INFERENCE pipeline\n",
    "- `2b) TRAIN vs INFERENCE` versions</u> `Reuse (Bronze->Silver->Gold) pipepline`, for both TRAIN preprocessing, and INFERENCE \n",
    "    - Benefits: Inference with different MODEL version, on data from the same day/time, (to compare scoring etc)\n",
    "    - How? ESMLDataset have context self awareness, and `knows WHERE and HOW to load/save data`\n",
    "- `2c) BATCH CONFIG`: Turn on/off features on ALL datasets\n",
    "    - Accelerate setup: `Datadrift, Time series traits, Smart noise, etc`\n",
    "    - Share refined data back to its \"origin/non-projectbased structure\" easy: \n",
    "        - ESMLProject.ShareBack(ds.Silver)\n",
    "    - How? ESMProject controls all ESMDatasets, in a uniform way\n",
    "## ENTERPRISE Deployment of Models & Governance - MLOps  at scale\n",
    "- `3) DEV->TEST-PROD` (configs, compute, performance)\n",
    "    - ESML has config for 3 environemnts: Easy DEPLOY model across subscriptions and Azure ML Studio workspaces \n",
    "        - Save costs & time: \n",
    "            - `DEV` has cheaper compute performance for TRAIN and INFERENCE (batch, AKS)\n",
    "            - `DEV` has Quick-debug ML training (fast training...VS good scoring in TEST and PROD)\n",
    "        - How? ESML `AutoMLFactory` and `ComputeFactory`\n",
    "         \n",
    "\n",
    "### Q&A:\n",
    "- Q: Is ESML Machine learning specific? If I only want to refine some data...for integration, or report? \n",
    "- A: You can use this for just data refinement also: `Bronze->Silver->Gold` refinement.\n",
    "    - Benefits: Enterprise security, Read/write to datalake, easy to share refined data. \n",
    "    - Benefits: The tooling \"glued togehter\": Azure datafactory +  Azure Databricks (and Azure ML Studio pipelines if needed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.dev_test_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselayer_azure_ml_model import ESMLModelCompare\n",
    "\n",
    "current_env = p.dev_test_prod # dev\n",
    "target_env = \"dev\" # Does newly trained Model v3 in DEV, score better than Model v2 in TEST?\n",
    "print(\"promote model in DEV to TEST? (move to other Azure ML Studio Workspace)\")\n",
    "\n",
    "compare = ESMLModelCompare(p)\n",
    "promote,source_model_name,new_run_id,target_model_name, target_best_run_id,target_workspace,source_model = compare.compare_scoring_current_vs_new_model(target_env) # Compare DEV to TEST (or TEST to PROD)  (1min, 17sek VS 33sec)\n",
    "\n",
    "print(\"SCORING DRIFT: If new model scores better in DEV (new data, or new code), we can promote this to TEST & PROD \\n\")\n",
    "print(\"New Model: {} in environment {}\".format(target_model_name, p.dev_test_prod))\n",
    "print(\"Existing Model: {} in environment {}\".format(source_model_name,target_env))\n",
    "\n",
    "if (promote): # Can register=\"promote\" a model in same workspace (test->test), or also register in OTHER Azure ML workspace (test->prod)\n",
    "    if(p.dev_test_prod == target_env):\n",
    "        compare.register_active_model(target_env,source_model) # if SAME workspace this brings more \"metadata\" faster to the model registration (will  register with EXPERIMENT and RUNID)\n",
    "    else:\n",
    "        compare.register_model_in_correct_ws(target_env) # if REMOTE target workspace we can get same metadata, BUT, just takes performancewise longer. More lookups to \"source Run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config, model, best_run = p.get_active_model_inference_config(ws) #  AutoML support \n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, tags = p.get_gold_validate_Xy() # Get the X_test data, ESML knows the SPLIT and LABEL already (due to training)\n",
    "print(tags)\n",
    "\n",
    "df = p.call_webservice(p.ws, X_test,\"my_caller_id_tracker_guid\") # Auto-fetch key from keyvault, and calls the webservice\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
