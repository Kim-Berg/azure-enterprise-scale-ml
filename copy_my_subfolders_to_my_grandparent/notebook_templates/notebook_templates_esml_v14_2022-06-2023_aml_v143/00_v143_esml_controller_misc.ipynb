{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLProject\n",
    "import pandas as pd\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "p = ESMLProject() # Your project settings - knows Azure services, networking, lakedesign, identity mgmt, security, etc\n",
    "p.inference_mode = False\n",
    "\n",
    "auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "#auth = InteractiveLoginAuthentication(force=True, tenant_id = p.tenant)\n",
    "ws, config_name = p.authenticate_workspace_and_write_config(auth)\n",
    "\n",
    "p.active_model = 11\n",
    "p.ws = p.get_workspace_from_config() #2) Load DEV or TEST or PROD Azure ML Studio workspace\n",
    "p.connect_to_lake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/\")\n",
    "\n",
    "from esmlrt.interfaces.iESMLController import IESMLController\n",
    "from esmlrt.interfaces.iESMLModelCompare import IESMLModelCompare\n",
    "from esmlrt.interfaces.iESMLTestScoringFactory import IESMLTestScoringFactory\n",
    "from esmlrt.interfaces.iESMLTrainer import IESMLTrainer\n",
    "from esmlrt.runtime.ESMLController import ESMLController\n",
    "from esmlrt.runtime.ESMLModelCompare2 import ESMLModelCompare\n",
    "from esmlrt.runtime.ESMLTestScoringFactory2 import ESMLTestScoringFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../2_A_aml_pipeline/4_inference/batch/M11/\")\n",
    "from your_code.your_train_code import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = p.ws\n",
    "target_column_name = p.active_model[\"label\"]\n",
    "ml_type = p.active_model[\"ml_type\"]\n",
    "esml_modelname = p.model_folder_name\n",
    "esml_model_alias = p.ModelAlias\n",
    "esml_current_env  = p.dev_test_prod\n",
    "train_ds = p.GoldTrain\n",
    "validate_ds = p.GoldValidate\n",
    "test_ds = p.GoldTest\n",
    "all_envs = p.get_all_envs()\n",
    "\n",
    "secret_name_tenant = \"kv-msft-weu-dev-cmnai-tenant\"\n",
    "secret_name_sp_id = \"kv-secret-esml-project002-sp-id\"\n",
    "secret_name_sp_secret = \"kv-secret-esml-project002-sp-secret\"\n",
    "\n",
    "test_scoring = ESMLTestScoringFactory(ml_type) # You need to implement IESMLTestScoringFactory\n",
    "comparer = ESMLModelCompare(setting_path = \"../../\") # You need to implement IESMLModelCompare\n",
    "\n",
    "controller = ESMLController(comparer,test_scoring,\"project002\",esml_modelname, esml_model_alias,all_envs, secret_name_tenant,secret_name_sp_id,secret_name_sp_secret ) # IESMLController: you do not have to change/implemen this class. Dependency injects default or your class.\n",
    "controller.dev_test_prod = esml_current_env\n",
    "controller.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl.run import AutoMLRun\n",
    "\n",
    "automl_step_run_id = '8b7c996f-6937-4470-a42b-7e59d91f6d49'\n",
    "\n",
    "experiment_run = ws.experiments[controller.experiment_name] # Get the experiment. Alternatively: Experiment(workspace=source_workspace, name=experiment_name)\n",
    "automl_step_run = AutoMLRun(experiment_run, run_id = automl_step_run_id)\n",
    "best_run, fitted_model_1 = automl_step_run.get_output()\n",
    "\n",
    "promote_new_model,source_model_name,new_run_id,target_model_name, target_best_run_id,target_workspace,source_model = comparer.compare_scoring_current_vs_new_model(\n",
    "    new_run_id = automl_step_run_id, # main_run.id,\n",
    "    current_ws = ws,\n",
    "    current_environment = esml_current_env,\n",
    "    target_environment = esml_current_env,\n",
    "    target_workspace = ws,\n",
    "    experiment_name = controller.experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(IESMLController.esml_status_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.dev_test_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment, model,main_run, best_automl_run,fitted_model = controller.get_latest_run_via_PipelineMetaDataset(ws,controller.experiment_name, controller.dataset_gold_train_runinfo_name_azure)\n",
    "print(\"     ###    \")\n",
    "print(\"Experiment:\", experiment.name)\n",
    "print(\"Pipeline RUN:\", main_run.id)\n",
    "print(\"Best RUN:\",best_automl_run)\n",
    "print (\"...and...\")\n",
    "\n",
    "print(\"AML Model()\", type(model))\n",
    "print(\"Fitted model\", type(fitted_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment, model,main_run, best_run,fitted_model = IESMLController.get_best_model_run_fitted_model_Dev(ws,controller.experiment_name)\n",
    "print(experiment.name)\n",
    "print(model.name)\n",
    "print(main_run.id)\n",
    "try:\n",
    "    print(model.tags['esml_time_updated'])\n",
    "except:\n",
    "    print(\"Not an ESML registered model..\")\n",
    "    \n",
    "print (\"...and...\")\n",
    "print(type(best_run))\n",
    "print(type(fitted_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment, model,main_run, best_run,fitted_model = IESMLController.get_best_model_run_fitted_model_Dev(ws,controller.experiment_name)\n",
    "print(experiment.name)\n",
    "print(model.name)\n",
    "print(main_run.id)\n",
    "try:\n",
    "    print(model.tags['esml_time_updated'])\n",
    "except:\n",
    "    print(\"Not an ESML registered model..\")\n",
    "    \n",
    "print (\"...and...\")\n",
    "print(type(best_run))\n",
    "print(type(fitted_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_highest_version, run_id_tag, model_name_tag = IESMLController.get_best_model_via_modeltags_only_DevTestProd(ws,controller.experiment_name,filter_on_version=None,sort_by_created_instead_of_version=False) # 3:39 LAMBDA\n",
    "print(model_highest_version.name)\n",
    "print(run_id_tag)\n",
    "print(model_name_tag)\n",
    "# 4.24 Datetime sort\n",
    "try:\n",
    "    print(model_highest_version.version) # AutoML00b58dfed0 (v17) (manual run) VS 11_diabetes_model_reg(v 11) -> Both are TAGGED with experiment_name=11_diabetes_model_reg\n",
    "    print(model_highest_version.created_time)\n",
    "    print(model_highest_version.tags['esml_time_updated'])\n",
    "except:\n",
    "    print(\"Not an ESML registered model..\")\n",
    "\n",
    "print(\"model_highest_version.run is None: {}\".format((model_highest_version.run is None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "all_models = Model.list(workspace=ws)\n",
    "filtered_list = list(filter(lambda r: (r.tags.get(\"experiment_name\") == controller.experiment_name), all_models))\n",
    "\n",
    "filtered_list.sort(key=lambda r: r.version,reverse=True)\n",
    "            \n",
    "if (len(filtered_list) > 0): # IF we found any...\n",
    "    model_highest_version = filtered_list[0]\n",
    "\n",
    "print(model_highest_version.version)\n",
    "print(model_highest_version.created_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_highest_version.created_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get TEST SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  label,ws, GoldTest, model, fitted_model, source_best_run/run\n",
    "experiment, model,main_run, best_automl_run,fitted_model = IESMLController.get_best_model_run_fitted_model_Dev(ws,controller.experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_automl_run.properties['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, r2, mean_abs_percent_error,mae,spearman_correlation,plt, dummy = test_scoring.get_test_scoring_8(ws,target_column_name,test_ds,fitted_model,best_automl_run,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGISTER model in DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment, model2,main_run, best_automl_run,fitted_model = IESMLController.get_best_model_run_fitted_model_Dev(ws,controller.experiment_name) # Get model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registered_in_target = controller.register_model(source_ws=ws, target_env=\"dev\", source_model_to_copy_tags_from=model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGISTER model from DEV to TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registered_in_target = controller.register_model(source_ws=ws, target_env=\"test\", source_model_to_copy_tags_from=model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-2-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment, model,main_run, best_automl_run,fitted_model = IESMLController.get_best_model_run_fitted_model_Dev(ws,controller.experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esml_modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_compare_register(ws,target_column_name,esml_modelname,esml_model_alias, esml_current_env, train_ds,validate_ds,test_ds):\n",
    "    test_scoring = None # IESMLTestScoringFactory\n",
    "    comparer = None # IESMLModelCompare\n",
    "    trainer = None # IESMLTrainer\n",
    "\n",
    "    # CUSTOMIZE ############### Optinonal: You can CUSTOMIZE, by implementing your own CLASS that supports interfaces/abstract classes: IESMLTestScoringFactory,IESMLModelCompare\n",
    "    ml_type = \"regression\"\n",
    "    test_scoring = ESMLTestScoringFactory(ml_type) # You need to implement IESMLTestScoringFactory\n",
    "    comparer = ESMLModelCompare(setting_path = \"\") # You need to implement IESMLModelCompare\n",
    "    # CUSTOMIZE END ###############\n",
    "\n",
    "    secret_name_tenant = \"kv-msft-weu-dev-cmnai-tenant\"\n",
    "    secret_name_sp_id = \"kv-secret-esml-project002-sp-id\"\n",
    "    secret_name_sp_secret = \"kv-secret-esml-project002-sp-secret\"\n",
    "\n",
    "    controller = ESMLController(comparer,test_scoring,\"project002\",esml_modelname, esml_model_alias, secret_name_tenant,secret_name_sp_id,secret_name_sp_secret) # IESMLController: you do not have to change/implemen this class. Dependency injects default or your class.\n",
    "    controller.dev_test_prod = esml_current_env\n",
    "\n",
    "    ##1 ) Get \"current\" 'last_gold_training_run' [pipeline_run_id, training_data_used]\n",
    "\n",
    "    experiment, model,main_run, best_automl_run,fitted_model_1 = IESMLController.get_best_model_run_fitted_model_Dev(ws,controller.experiment_name)\n",
    "\n",
    "    # ITrainer: Defaults to using AutoML. Optionally you can implement this. Else you need to implement ITrainer in 'YourTrainer' class\n",
    "    trainer = Trainer(model.name,esml_modelname,esml_model_alias, esml_current_env, ml_type,train_ds,validate_ds,test_ds)\n",
    "    train_run, aml_model,fitted_model_2 = trainer.train(train_ds,validate_ds)\n",
    "    \n",
    "    #  label,ws, GoldTest, model, fitted_model, source_best_run/run\n",
    "    rmse, r2, mean_abs_percent_error,mae,spearman_correlation,plt, dummy = test_scoring.get_test_scoring_8(ws,target_column_name,test_ds,fitted_model_1,best_automl_run,model)\n",
    "\n",
    "    next_environment = controller.get_next_environment()\n",
    "\n",
    "    #  current_ws,current_environment, target_environment,target_workspace, experiment_name)\n",
    "    target_ws = controller.get_target_workspace(current_environment = esml_current_env, current_ws = ws, target_environment = esml_current_env)\n",
    "\n",
    "    ## 2) COMPARE if better\n",
    "\n",
    "    promote_new_model,source_model_name,new_run_id,target_model_name, target_best_run_id,target_workspace,source_model = comparer.compare_scoring_current_vs_new_model(\n",
    "        new_run_id = main_run.id,\n",
    "        current_ws = ws,\n",
    "        current_environment = esml_current_env,\n",
    "        target_environment = esml_current_env,\n",
    "        target_workspace = target_ws,\n",
    "        experiment_name = trainer.experiment_name)\n",
    "\n",
    "\n",
    "    print(\"compared once, 1 time, inner loop - Dev\")\n",
    "\n",
    "    ## 3) REGISTER model, if better\n",
    "\n",
    "    if (promote_new_model == True): # Better than all in DEV?! (Dev or Test,  is usually current_env)\n",
    "        model_registered_in_target = controller.register_model(source_ws=ws, target_env=esml_current_env, source_model_to_copy_tags_from=model)\n",
    "        print(\"registered in DEV\")\n",
    "\n",
    "        # Better than all in DEV, Lets check if its better than all in TEST? (or prod)\n",
    "        next_environment = controller.get_next_environment() # Test, or PROD\n",
    "        promote_new_model,source_model_name,new_run_id,target_model_name, target_best_run_id,target_workspace,source_model = comparer.compare_scoring_current_vs_new_model(\n",
    "            new_run_id = main_run.id,\n",
    "            current_ws = ws,\n",
    "            current_environment = esml_current_env,\n",
    "            target_environment = next_environment,\n",
    "            target_workspace = target_ws,\n",
    "            experiment_name = trainer.experiment_name)\n",
    "\n",
    "        print(\"Compared 2nd time - Outer loop\")\n",
    "        if (promote_new_model == True):\n",
    "            model_registered_in_target = controller.register_model(source_ws=ws, target_env=\"test\", source_model_to_copy_tags_from=model)\n",
    "            print(\"Registered in TEST\")\n",
    "\n",
    "train_test_compare_register(ws,target_column_name,esml_modelname,esml_model_alias, esml_current_env, train_ds,validate_ds,test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET: See Run info from last gold scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "# p = ESMLProject()\n",
    "# ...\n",
    "# ...p.connect_to_lake()\n",
    "meta_dataset = Dataset.get_by_name(p.ws, name=\"M10_GOLD_SCORED_RUNINFO\")\n",
    "meta_dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('azure_automl_esml_v144')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4a3f6f829c0fbf992fdd78de6ec4e694e293d154a9b96895f90a426de0ee97e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
