{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always run thic CELL below\n",
    "- To attach ESML controlplane to your project\n",
    "- To point at `template-data` for the pipelinbe to know the schema of data\n",
    "- To init the ESMLPieplinefactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lake_settings.json with ESML version 1.4 - Models array support including LABEL\n",
      "\n",
      " ---- Q: WHICH files are generated as templates, for you to EDIT? ---- \n",
      "A: These files & locations:\n",
      "File to EDIT (step: IN_2_SILVER_1): ../../../2_A_aml_pipeline/4_inference/batch/M11/in2silver_ds01_diabetes.py\n",
      "File to EDIT (step: IN_2_SILVER_2): ../../../2_A_aml_pipeline/4_inference/batch/M11/in2silver_ds02_other.py\n",
      "File to EDIT (step: SILVER_MERGED_2_GOLD): ../../../2_A_aml_pipeline/4_inference/batch/M11/silver_merged_2_gold.py\n",
      "File to EDIT (step: SCORING_GOLD): ../../../2_A_aml_pipeline/4_inference/batch/M11/scoring_gold.py\n",
      "File to EDIT (step: TRAIN_SPLIT_AND_REGISTER): ../../../2_A_aml_pipeline/4_inference/batch/M11/train_split_and_register.py\n",
      "File to EDIT (step: TRAIN_MANUAL): ../../../2_A_aml_pipeline/4_inference/batch/M11/train_manual.py\n",
      "File to EDIT (step: TRAIN_AUTOML): ../../../2_A_aml_pipeline/4_inference/batch/M11/train_post_automl_step.py\n",
      "File to EDIT a lot (reference in step-scripts Custom code): ../../../2_A_aml_pipeline/4_inference/batch/M11/your_code/your_custom_code.py\n",
      "\n",
      " ---- WHAT model to SCORE with, & WHAT data 'date_folder'? ---- \n",
      "InferenceModelVersion (model version to score with): 1\n",
      "Date_scoring_folder (data to score) : 1000-01-01 10:35:01.243860\n",
      "ESML environment: dev\n",
      "Inference mode (self.batch_pipeline_parameters[4]): 0\n",
      "\n",
      " ---- ESML Datalake locations: ESML Datasets (IN-data) ---- \n",
      "Name (lake folder): ds01_diabetes and AzureName IN: M11_ds01_diabetes_train_IN\n",
      "IN projects/project002/11_diabetes_model_reg/train/ds01_diabetes/in/dev/1000/01/01/\n",
      "Bronze projects/project002/11_diabetes_model_reg/train/ds01_diabetes/out/bronze/dev/\n",
      "Silver projects/project002/11_diabetes_model_reg/train/ds01_diabetes/out/silver/dev/\n",
      "\n",
      "Name (lake folder): ds02_other and AzureName IN: M11_ds02_other_train_IN\n",
      "IN projects/project002/11_diabetes_model_reg/train/ds02_other/in/dev/1000/01/01/\n",
      "Bronze projects/project002/11_diabetes_model_reg/train/ds02_other/out/bronze/dev/\n",
      "Silver projects/project002/11_diabetes_model_reg/train/ds02_other/out/silver/dev/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLProject\n",
    "from baselayer_azure_ml_pipeline import ESMLPipelineFactory, esml_pipeline_types\n",
    "\n",
    "p = ESMLProject()\n",
    "p.inference_mode = False\n",
    "p.active_model = 11 # 10=titanic , 11=Diabetes\n",
    "p_factory = ESMLPipelineFactory(p)\n",
    "\n",
    "scoring_date = '1000-01-01 10:35:01.243860' # \n",
    "p_factory.batch_pipeline_parameters[1].default_value = scoring_date # overrides ESMLProject.date_scoring_folder.\n",
    "p_factory.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN_2_GOLD_TRAIN_AUTOML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override default CURATED environment = \"AzureML-AutoML-DNN\", \"AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu\"\n",
    "p_factory.use_curated_automl_environment = True\n",
    "p_factory.environment_name = \"AzureML-AutoML\" # Training[ \"AzureML-AutoML\", \"AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu\"]  Inference[\"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\",\"AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creates template step_files.py for user to edit at:\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M11/in2silver_ds01_diabetes.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M11/in2silver_ds02_other.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M11/silver_merged_2_gold.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M11/scoring_gold.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M11/train_split_and_register.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M11/train_manual.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M11/train_post_automl_step.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M11/your_code/your_custom_code.py\n",
      "Using GEN2 as Datastore\n",
      "ESML will auto-create a compute...\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Using a model specific cluster, per configuration in project specific settings, (the integer of 'model_number' is the base for the name)\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster p02-m11weu-dev for project and environment, using it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "image_build_compute = p02-m11weu-dev\n",
      "Reusing existing compute...\n",
      "create_gold_train_step: inference_mode=False\n",
      "ESML-train_path_out = \n",
      "Loading AutoML config settings from: dev\n",
      "Tryingt to get CURRENT leader model from Azure ML Studio workspace - remotely.This might be the first time training model. then None is returned \n",
      "\n",
      "It was not an AutoMLRun() Lets init it as a regular Run()\n",
      "train_folder_template_with_date_id: projects/project002/11_diabetes_model_reg/train/gold/dev/{id_folder}/\n"
     ]
    }
   ],
   "source": [
    "## BUILD\n",
    "p_factory.create_dataset_scripts_from_template(overwrite_if_exists=True) # Do this once, then edit them manually. overwrite_if_exists=False is DEFAULT\n",
    "batch_pipeline = p_factory.create_batch_pipeline(esml_pipeline_types.IN_2_GOLD_TRAIN_AUTOML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute_pipeline (scoring): Inference_mode: 0\n",
      "-Scoring data, default value 1000-01-01 10:35:01.243860\n",
      "Created step IN 2 SILVER - ds01_diabetes [ca71fa78][0054e7ea-e784-4cec-83b3-bc30c3b79ef0], (This step will run and generate new outputs)\n",
      "Created step IN 2 SILVER - ds02_other [bca17c5d][8006bea5-11e8-480d-a461-bd668dcd5140], (This step will run and generate new outputs)\n",
      "Created step SILVER MERGED 2 GOLD [db71781a][c9d09aae-3f02-44cc-9b83-780b8962859e], (This step will run and generate new outputs)\n",
      "Created step SPLIT AND REGISTER datasets [0e753fec][1b946c81-fffe-4c6a-a286-3e7aeac906c5], (This step will run and generate new outputs)\n",
      "Created step AutoML TRAIN in  [dev] [7e443163][7adf5f7b-d250-4a4f-8e8f-ae8ec3b53514], (This step will run and generate new outputs)\n",
      "Created step [dev]Calculate SCORING on TEST_SET, COMPARE & REGISTER model in [dev] & PROMOTE to [test] [a9d9cc64][135690f4-bcdd-42ad-8673-1a4a230d9bfd], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 224cbaa3-6a29-4358-a3c5-4c20559e943b\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/224cbaa3-6a29-4358-a3c5-4c20559e943b?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/MSFT-WEU-EAP_PROJECT02_AI-DEV-RG/workspaces/msft-weu-DEV-eap-proj02_ai-amls&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Pipeline submitted for execution!\n",
      " ### \n",
      "PipelineRunId: 224cbaa3-6a29-4358-a3c5-4c20559e943b\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/224cbaa3-6a29-4358-a3c5-4c20559e943b?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/MSFT-WEU-EAP_PROJECT02_AI-DEV-RG/workspaces/msft-weu-DEV-eap-proj02_ai-amls&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN\n",
    "pipeline_run = p_factory.execute_pipeline(batch_pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_pipe.name 11_diabetes_model_reg_pipe_IN_2_GOLD_SCORING_EP_6\n",
      "pub_pipe.id 5ecadc66-0895-4633-b7de-2fd3df5812ce\n",
      "pub_pipe.name 11_diabetes_model_reg_pipe_IN_2_GOLD_EP\n",
      "pub_pipe.id 8843bea2-7c7e-4738-9028-a16f89f7d6e7\n",
      "pub_pipe.name 11_diabetes_model_reg_pipe_IN_2_GOLD_SCORING_EP_5\n",
      "pub_pipe.id 5d828765-e496-4df6-9701-4581c31990e6\n",
      "pub_pipe.name 11_diabetes_model_reg_batch_scoring_pipe_EP_4\n",
      "pub_pipe.id e5ed3b30-89fd-4b70-a2a0-403451ea2228\n",
      "pub_pipe.name 11_diabetes_model_reg_pipe_IN_2_GOLD\n",
      "pub_pipe.id 5c1c0622-2f18-4380-865f-b5df380f2345\n",
      "pub_pipe.name 10_titanic_model_clas_batch_scoring_pipe_EP_4\n",
      "pub_pipe.id aa67ac38-da18-4b2d-973a-df87998aa1b6\n",
      "pub_pipe.name 11_diabetes_model_reg_batch_scoring_pipe_EP_1\n",
      "pub_pipe.id c21397ba-8e26-4582-b7eb-0cf9bee5cc0c\n"
     ]
    }
   ],
   "source": [
    "# PUBLISH\n",
    "published_pipeline, endpoint = p_factory.publish_pipeline(batch_pipeline,\"_1\") # \"_1\" is optional    to create a NEW pipeline with 0 history, not ADD version to existing pipe & endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info - to use  in Azure data factory: `published_pipeline.id` (if private Azure ML workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) Fetch scored data: Below needed for Azure Data factory PIPELINE activity (Pipeline OR Endpoint. Choose the latter\n",
      "- Endpoint ID\n",
      "Endpoint ID:  681339bb-c47c-4af3-b408-df8155395f74\n",
      "Endpoint Name:  11_diabetes_model_reg_pipe_IN_2_GOLD_TRAIN_EP_1\n",
      "Experiment name:  11_diabetes_model_reg_pipe_IN_2_GOLD_TRAIN\n",
      "In AZURE DATA FACTORY - This is the ID you need, if using PRIVATE LINK, private Azure ML workspace.\n",
      "-You need PIPELINE id, not pipeline ENDPOINT ID ( since cannot be chosen in Azure data factory if private Azure ML)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'af7a8f47-7cda-47cc-afc7-c71cce7fecd6'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2) Fetch scored data: Below needed for Azure Data factory PIPELINE activity (Pipeline OR Endpoint. Choose the latter\") \n",
    "print (\"- Endpoint ID\")\n",
    "print(\"Endpoint ID:  {}\".format(endpoint.id))\n",
    "print(\"Endpoint Name:  {}\".format(endpoint.name))\n",
    "print(\"Experiment name:  {}\".format(p_factory.experiment_name))\n",
    "\n",
    "print(\"In AZURE DATA FACTORY - This is the ID you need, if using PRIVATE LINK, private Azure ML workspace.\")\n",
    "print(\"-You need PIPELINE id, not pipeline ENDPOINT ID ( since cannot be chosen in Azure data factory if private Azure ML)\")\n",
    "published_pipeline.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('azure_automl_esml_v144')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4a3f6f829c0fbf992fdd78de6ec4e694e293d154a9b96895f90a426de0ee97e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
