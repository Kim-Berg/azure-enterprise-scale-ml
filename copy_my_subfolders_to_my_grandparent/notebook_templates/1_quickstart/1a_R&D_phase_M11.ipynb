{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R&D phase: About this notebook\n",
    "- Purpose: TRAINS a model with Azure AutoML and with AZURE compute cluster and calculates test_set scoring, automatically compares if newly trained model is better.\n",
    "    - To iteratively try different ML-algorithms see what's best, change performance settings, train again.\n",
    "    - Also to try different apporoaches, classification or regression approach - which is better for the use case.\n",
    "\n",
    "- Q: `WHEN to move on form R&D phase to PRODUCTION phase notebook?`\n",
    "    - When you are happy with the MODEL (or if you have a big dataset that requires pipeline for training) - then go to the next notebook `2a_PRODUCTION_phase` to create PIPELINES: \n",
    "        - PRODUCTION PHASE & MLOps requires 1 `training pipeline`, and a `scoring pipeline` or `scoring online endpoint`, for inference \n",
    "- This notebook - Details:\n",
    "    - 1) Automaps data as Azure ML datasets. Based on your `lake_settings.json`\n",
    "    - 2) Splits the GOLD data into 3 buckets. \n",
    "        - NB this is done with local compute, not Azure, use \n",
    "             - Option 1: `2a_PRODUCTION_phase` training pipeline if data is too big for local RAM memory\n",
    "             - Option 2: Stay in this notebook & local split of data, but increase RAM memory of your/this Azure VM developer (DSVM) computer.\n",
    "             - Option 2: Stay in this notebook & local split of data, but reduce data size. Only use a sample .parquet (or .csv) file in the IN-folder.\n",
    "    - 3) Trains model\n",
    "    - 4) Registers model\n",
    "    - 5) Calculate test_set scoring\n",
    "    - 6) Deploys model - ONLINE endpoint to AKS\n",
    "    - 7) Inference: Smoke testing, using the ONLINE endpoint - get result back, saves the result to datalake also\n",
    "    - DONE.\n",
    "    \n",
    "- This notebook is called: `M10_v143_esml_classification_1_train_env_dev.ipynb` in the notebook_templates folder\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login / Switch DEV_TEST_PROD environment (1-timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from esml import ESMLProject\n",
    "\n",
    "p = ESMLProject()\n",
    "p.dev_test_prod=\"dev\"\n",
    "\n",
    "print(p.tenant)\n",
    "print(p.workspace_name) # self.workspace_name,subscription_id = self.subscription_id,resource_group = self.resource_group\n",
    "print(p.subscription_id)\n",
    "print(p.resource_group)\n",
    "\n",
    "auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "#auth = InteractiveLoginAuthentication(force=True, tenant_id = p.tenant)\n",
    "ws, config_name = p.authenticate_workspace_and_write_config(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) ESML - TRAIN Classification, TITANIC model, and DEPLOY with predict_proba scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lake_settings.json with ESML version 1.4 - Models array support including LABEL\n",
      "Environment: dev\n",
      "Inference version: 1\n",
      "\n",
      " - ds01_diabetes\n",
      "projects/project002/11_diabetes_model_reg/train/ds01_diabetes/in/dev/1000/01/01/\n",
      "projects/project002/11_diabetes_model_reg/train/ds01_diabetes/out/bronze/dev/\n",
      "projects/project002/11_diabetes_model_reg/train/ds01_diabetes/out/silver/dev/\n",
      "\n",
      " - ds02_other\n",
      "projects/project002/11_diabetes_model_reg/train/ds02_other/in/dev/1000/01/01/\n",
      "projects/project002/11_diabetes_model_reg/train/ds02_other/out/bronze/dev/\n",
      "projects/project002/11_diabetes_model_reg/train/ds02_other/out/silver/dev/\n",
      " \n",
      "\n",
      "Training GOLD (p.GoldPath)\n",
      "projects/project002/11_diabetes_model_reg/train/gold/dev/\n",
      " \n",
      "\n",
      "[A) USAGE]: to_score_folder, scored_folder, date_folder = p.get_gold_scored_unique_path()\n",
      "A)INFERENCE ONLINE: GOLD to score (example if realtime - today)\n",
      "projects/project002/11_diabetes_model_reg/inference/1/gold/dev/2022_10_14/dd9fe698a4784cb6b0bb0d169df7413a/\n",
      " \n",
      "\n",
      "A)INFERENCE ONLINE: GOLD scored (example if realtime today)\n",
      "projects/project002/11_diabetes_model_reg/inference/1/scored/dev/2022_10_14/dd9fe698a4784cb6b0bb0d169df7413a/\n",
      " \n",
      "\n",
      "[B) USAGE]: to_score_folder_batch, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder)\n",
      "B)INFERENCE BATCH: GOLD to score (example batch, datetime from config)\n",
      "projects/project002/11_diabetes_model_reg/inference/1/gold/dev/1000_01_01/8ffb36a70387418a9f7c04a6dbb211f1/\n",
      " \n",
      "\n",
      "B)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\n",
      "projects/project002/11_diabetes_model_reg/inference/1/scored/dev/1000_01_01/8ffb36a70387418a9f7c04a6dbb211f1/\n",
      " \n",
      "\n",
      "C) INFERENCE BATCH (SCENARIO 2): TODAY I scored data from X days AGO  (second datefolder from config - X days ago)\n",
      "projects/project002/11_diabetes_model_reg/inference/1/gold/dev/1000_01_01/8ffb36a70387418a9f7c04a6dbb211f1/1000_01_01/\n",
      "projects/project002/11_diabetes_model_reg/inference/1/scored/dev/1000_01_01/8ffb36a70387418a9f7c04a6dbb211f1/1000_01_01/\n",
      " \n",
      "\n",
      "ENVIRONMENT - DEV, TEST, or PROD?  [USAGE: p.dev_test_prod]\n",
      "ACTIVE ENVIRONMENT = dev\n",
      "ACTIVE subscription = ca0a8c40-b06a-4e4e-8434-63c03a1dee34\n",
      "- MSFT-WEU-EAP_PROJECT02_AI-DEV-RG\n",
      "- msft-weu-DEV-eap-proj02_ai-amls\n",
      "- westeurope\n",
      "- MSFT-WEU-EAP_CMN_AI-DEV-RG\n",
      "Active vNet: msft-weu-dev-cmnai-vnet\n",
      "Active SubNet: \n",
      "[USAGE] for the above: p.vNetForActiveEnvironment()\n",
      "Active Lake (storage account)  msftweudevcmnai2\n",
      "[USAGE] for the above: p.getLakeForActiveEnvironment()\n",
      "AML for docker: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLProject\n",
    "import pandas as pd\n",
    "\n",
    "param_esml_env = \"dev\" \n",
    "param_inference_model_version = \"1\" # DATALAKE(my_model/inference/active) | settings/project_specific/active/active_scoring_in_folder.json\n",
    "param_scoring_folder_date = \"1000-01-01 00:00:01.243860\" # DATALAKE(my_model/inference/active) | settings/project_specific/active/active_scoring_in_folder.json\n",
    "param_train_in_folder_date = \"1000-01-01 00:00:01.243860\" # DATALAKE(my_model/train/active) | settings/project_specific/active/active_in_folder.json\n",
    "\n",
    "p = ESMLProject(param_esml_env,param_inference_model_version,param_scoring_folder_date,param_train_in_folder_date)\n",
    "#p = ESMLProject() # Alternatively use empty contructor, which takes parameters from settings\\project_specific\\model\\active\\active_in_folder.json\n",
    "\n",
    "p.active_model = 11\n",
    "p.inference_mode = False\n",
    "p.ws = p.get_workspace_from_config() #2) Load DEV or TEST or PROD Azure ML Studio workspace\n",
    "p.verbose_logging = False\n",
    "p.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregister_all_datasets=False\n",
    "if(unregister_all_datasets):\n",
    "    p.unregister_all_datasets(p.ws) # For DEMO purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feature_engieering():\n",
    "    # Feture engineering: Bronze 2 Gold - working with Azure ML Datasets with Bronze, Silver, Gold concept\n",
    "    esml_dataset = p.DatasetByName(\"ds01_diabetes\") # Get dataset\n",
    "    df_bronze = esml_dataset.Bronze.to_pandas_dataframe()\n",
    "    p.save_silver(esml_dataset,df_bronze) #Bronze -> Silver\n",
    "\n",
    "    esml_dataset2 = p.DatasetByName(\"ds02_other\") # Get dataset\n",
    "    df_bronze2 = esml_dataset2.Bronze.to_pandas_dataframe()\n",
    "    p.save_silver(esml_dataset2,df_bronze2) #Bronze -> Silver\n",
    "\n",
    "    df = esml_dataset.Silver.to_pandas_dataframe() \n",
    "    df_filtered = df[df.AGE > 0.015] \n",
    "    gold = p.save_gold(df_filtered)  #Silver -> Gold\n",
    "    return gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GEN2 as Datastore\n",
      "Searching for setting in ESML datalake...\n",
      "ESML in-folder settings override = TRUE \n",
      " - Found settings in the ESML AutoLake  [active_in_folder.json,active_scoring_in_folder.json], to override ArgParse/GIT config with.\n",
      " - TRAIN in date:  1000/01/01\n",
      " - INFERENCE in date: 2021/06/08 and ModelVersion to score with: 1 (0=latest)\n",
      "Not 1st time. We have data mapped already...and splitted. Now connected to LAKE\n"
     ]
    }
   ],
   "source": [
    "datastore = None\n",
    "try:\n",
    "    datastore = p.connect_to_lake() # Connects to the correct ALDS GEN 2 storage account (DEV, TEST or PROD)\n",
    "    gold_train = p.GoldTrain\n",
    "    gold_train.name\n",
    "    print(\"Not 1st time. We have data mapped already...and splitted. Now connected to LAKE\")\n",
    "except: # If 1st time....no Gold exists, nor any mapping\n",
    "    print(\"1st time. Lets init, map what data we have in LAKE, as Azure ML Datasets\")\n",
    "    datastore = p.init() # 3) Automapping from datalake to Azure ML datasets\n",
    "    gold = test_feature_engieering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGE       SEX       BMI        BP        S1        S2        S3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         S4        S5        S6      Y  \n",
       "0 -0.002592  0.019908 -0.017646  151.0  \n",
       "1 -0.039493 -0.068330 -0.092204   75.0  \n",
       "2 -0.002592  0.002864 -0.025930  141.0  \n",
       "3  0.034309  0.022692 -0.009362  206.0  \n",
       "4 -0.002592 -0.031991 -0.046641  135.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.Gold.to_pandas_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY - step 1\n",
    "- ESML has now `Automap` and `Autoregister` Azure ML Datasets as: `IN, SILVER, BRONZE, GOLD`\n",
    "- ESML has read configuration for correct environment (DEV, TEST, PROD). \n",
    "    - Both small customers, and large Enterprise customers often wants:  DEV, TEST, PROD in `diffferent Azure ML workspaces` (and different subscriptions)\n",
    "- User has done feature engineering, and saved GOLD `p.save_gold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in GOLD 442\n"
     ]
    }
   ],
   "source": [
    "print(\"rows in GOLD {}\".format(p.Gold.to_pandas_dataframe().shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT option A) ESML default split logic, which you can override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "M10_GOLD_TRAIN, M10_GOLD_VALIDATE, M10_GOLD_TEST = p.split_gold_3(0.6,label=p.active_model[\"label\"],stratified=False) # Splits and Auto-registers as AZUREM ML Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT option B) Use YOUR split logic, override the default\n",
    "- You need to create your own class (ESMLSplitter is just an example class) such as MySplitter(IESMLSplitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/\")\n",
    "\n",
    "from esmlrt.interfaces.iESMLSplitter import IESMLSplitter # Just for reference to see where the abstract class exists\n",
    "from esmlrt.runtime.ESMLSplitter import ESMLSplitter1 # Point at your own code/class here instead..that needst to implement the IESMLSplitter class\n",
    "\n",
    "my_IESMLSplitter = ESMLSplitter1()\n",
    "M10_GOLD_TRAIN, M10_GOLD_VALIDATE, M10_GOLD_TEST = p.split_gold_3(train_percentage=0.6,label=p.active_model[\"label\"],stratified=False,override_with_custom_iESMLSplitter=my_IESMLSplitter) # Splits and Auto-registers as AZUREM ML Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN_2_GOLD\n",
    "- If just wanting to refine data to GOLD, for a Power BI report (No ML involved)\n",
    "- Scenario: You want to refine data from \"IN_2_GOLD\" with an easy way to READ/WRITE data (using the enterprise datalake via ESML AutoLake and ESML SDK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.GoldTrain.to_pandas_dataframe().head()  # Azure ML Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) `ESML` Train model in `5 codelines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We are in environment {}\".format(p.dev_test_prod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at our AutoML performance settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_performance_config = p.get_automl_performance_config() # 1)Get config, for active environment (dev,test or prod)\n",
    "automl_performance_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at our label, and our machine learning task type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Label is: {}'.format(p.active_model[\"label\"]))\n",
    "print('ml_type / task is: {}'.format(p.active_model[\"ml_type\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets TRAIN with AutoML & Azure compute cluster (M11 demo takes ~ 10-15min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esml import ESMLProject\n",
    "from baselayer_azure_ml import AutoMLFactory,azure_metric_regression,azure_metric_classification\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_performance_config = p.get_automl_performance_config() # 1)Get config, for active environment (dev,test or prod)\n",
    "aml_compute = p.get_training_aml_compute(p.ws) # 2)Get compute, for active environment\n",
    "\n",
    "automl_config = AutoMLConfig(task = p.active_model[\"ml_type\"], # 4) Override the ENV config, for model(that inhertits from enterprise DEV_TEST_PROD config baseline)\n",
    "                            primary_metric = azure_metric_regression.MAE, #  Note: Regression[MAE, RMSE,R2,Spearman] Classification[AUC,Accuracy,Precision,Precision_avg,Recall]\n",
    "                            compute_target = aml_compute,\n",
    "                            training_data = p.GoldTrain, # is 'train_6' pandas dataframe, but as an Azure ML Dataset\n",
    "                            experiment_exit_score = '0.308', # DEMO purpose. remove experiment_exit_score if you want to have good accuracy (put a comment # on this row to remove it)\n",
    "                            label_column_name = p.active_model[\"label\"],\n",
    "                            **automl_performance_config\n",
    "                        )\n",
    "\n",
    "best_run, fitted_model, experiment = AutoMLFactory(p).train_as_run(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Production purpose: \"once and only once\": Wrap code\n",
    "- 3 Callers: MLOps, AMLPipeline, and this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../2_A_aml_pipeline/4_inference/batch/M10/your_code/\")\n",
    "from your_custom_code import M01In2GoldProcessor\n",
    "\n",
    "#p.init()\n",
    "esml_dataset1 = p.DatasetByName(\"ds01_titanic\") # Get dataset 1\n",
    "df_bronze = esml_dataset1.Bronze.to_pandas_dataframe()\n",
    "silver1 = p.save_silver(esml_dataset1,df_bronze) #Bronze -> Silver\n",
    "\n",
    "esml_dataset2 = p.DatasetByName(\"ds02_haircolor\") # Get dataset 2\n",
    "df_bronze2 = esml_dataset2.Bronze.to_pandas_dataframe()\n",
    "silver2 = p.save_silver(esml_dataset2,df_bronze2) #Bronze -> Silver\n",
    "\n",
    "df1 = M01In2GoldProcessor().M01_ds01_process_in2silver(silver1.to_pandas_dataframe())  # You can then copy this statement in your pipeline-step \"in2silver_ds01...py\"\n",
    "df2 = M01In2GoldProcessor().M01_ds02_process_in2silver(silver2.to_pandas_dataframe())  # You can then copy this statement in your pipeline-step \"in2silver_ds02...py\"\n",
    "\n",
    "merged_gold = M01In2GoldProcessor().M01_merge_silvers(df1,df2) # # You can then copy this statement in your pipeline-step \"silver_merged_2_gold.py\"\n",
    "p.save_gold(merged_gold).to_pandas_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b) ESML Scoring Drift/Concept Drift: Compare with `1-codeline`: Promote model or not? If better, then `Register model`\n",
    "- `IF` newly trained model in `current` environment (`DEV`, `TEST` or `PROD`) scores BETTER than existing model in `target` environment, then `new model` can be registered and promoted.\n",
    "- Q: Do we have `SCORING DRIFT / CONCEPT DRIFT?`\n",
    "- Q: Is a model trained on NEW data better? IS the one in production degraded? (not fit for the data it scores - real world changed, other CONCEPT)\n",
    "- A: - Lets check. Instead of `DataDrift`, lets look at `actual SCORING` on new data (and/or new code, feature engineering) - See if we should PROMOTE newly trained model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"current AI Factory environment: '{}' - AML WS: '{}'\".format(p.dev_test_prod, p.ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselayer_azure_ml_model import ESMLModelCompare\n",
    "\n",
    "current_env = p.dev_test_prod # dev\n",
    "target_env = \"dev\" # Does newly trained Model v3 in DEV, score better than Model v2 in TEST?\n",
    "print(\"promote model in DEV to TEST? (move to other Azure ML Studio Workspace)\")\n",
    "\n",
    "compare = ESMLModelCompare(p)\n",
    "promote,source_model_name,new_run_id,target_model_name, target_best_run_id,target_workspace,source_model = compare.compare_scoring_current_vs_new_model(target_env) # Compare DEV to TEST (or TEST to PROD)  (1min, 17sek VS 33sec)\n",
    "\n",
    "print(\"SCORING DRIFT: If new model scores better in DEV (new data, or new code), we can promote this to TEST & PROD \\n\")\n",
    "print(\"New Model: {} in environment {}\".format(target_model_name, p.dev_test_prod))\n",
    "print(\"Existing Model: {} in environment {}\".format(source_model_name,target_env))\n",
    "\n",
    "if (promote): # Can register=\"promote\" a model in same workspace (test->test), or also register in OTHER Azure ML workspace (test->prod)\n",
    "    if(p.dev_test_prod == target_env):\n",
    "        compare.register_active_model(target_env,source_model) # if SAME workspace this brings more \"metadata\" faster to the model registration\n",
    "    else:\n",
    "        compare.register_model_in_correct_ws(target_env) # if REMOTE target workspace we can get same metadata, BUT, just takes performancewise longer. More lookups to \"source Run\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST SET SCORING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-set: Ensure we have a TEST_SET splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = p.active_model[\"label\"]\n",
    "try:\n",
    "    p.GoldTest.name\n",
    "except: \n",
    "    p.connect_to_lake() # p.init() + automap\n",
    "    train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW we can calcualate scoring on TEST_SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselayer_azure_ml import ESMLTestScoringFactory\n",
    "\n",
    "label = p.active_model[\"label\"]\n",
    "rmse, r2, mean_abs_percent_error,mae,spearman_corr,plt = ESMLTestScoringFactory(p).get_test_scoring_4_regression(label)\n",
    "print(\"RMSE:\")\n",
    "print(rmse)\n",
    "print()\n",
    "print(\"R2:\")\n",
    "print(r2)\n",
    "print()\n",
    "print(\"MAPE:\")\n",
    "print(mean_abs_percent_error)\n",
    "print()\n",
    "print(\"MAE:\")\n",
    "print(mae)\n",
    "print()\n",
    "print(\"Spearman:\")\n",
    "print(spearman_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('azure_automl_esml_v144')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4a3f6f829c0fbf992fdd78de6ec4e694e293d154a9b96895f90a426de0ee97e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
