{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRODUCTION phase: About this notebook\n",
    "- Purpose: Creates 1 AKS webservice, to serve the model as an ONLINE endpoint\n",
    "    - `AKS ONLINE Webservice:` Fetches the best trained model, Deployes that on an `AKS cluster`, always up and running, ready to be pinged and return results (via REST / Swagger, or Python SDK)\n",
    "\n",
    "## DETAILS - about this notebook and the 2 pipelines, generated            \n",
    "- 1) `Initiates ESMLProject` and sets `active model` and `active date folder`:\n",
    "- 2) `DEPLOY & SERVER: Fetched the BEST MODEL, and deploys on AKS`\n",
    "- 3) `Smoke testing: Fetches some data and calls the webservice` (smoke testing purpose - see that it works...)\n",
    "    - Gets test data\n",
    "    - Calls webservice, which both returns data via REST call, and ESML optionally also saves the returned result to datalake "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login / Switch DEV_TEST_PROD environment (1-timer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from esml import ESMLProject\n",
    "\n",
    "p = ESMLProject() # Will search in ROOT for your copied SETTINGS folder '../settings/model/active/active_scoring_in_folder.json',\n",
    "p.dev_test_prod=\"dev\"\n",
    "auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "#auth = InteractiveLoginAuthentication(force=True, tenant_id = p.tenant)\n",
    "ws, config_name = p.authenticate_workspace_and_write_config(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) `Initiates ESMLProject` and sets `active model` and `active date folder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/\")\n",
    "from esmlrt.interfaces.iESMLController import IESMLController\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLProject\n",
    "import pandas as pd\n",
    "\n",
    "p = ESMLProject() # Will search in ROOT for your copied SETTINGS folder '../settings/model/active/active_scoring_in_folder.json',\n",
    "p.active_model = 11\n",
    "p.inference_mode = False\n",
    "p.ws = p.get_workspace_from_config() #2) Load DEV or TEST or PROD Azure ML Studio workspace\n",
    "p.verbose_logging = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a) `DEPLOY`: Option A - Let ESML find BEST Model ( and its environment, scoring script) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config, model, best_run = IESMLController.get_best_model_inference_config(p.ws, p.model_folder_name, p.ModelAlias)\n",
    "service,api_uri, kv_aks_api_secret= p.deploy_model_as_private_aks_online_endpoint(model,inference_config,overwrite_endpoint=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b) `DEPLOY`: Option B - Inject YOUR selection of model and run, any model, override \"ESML best model logic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "from azureml.pipeline.core import PipelineRun\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "\n",
    "def get_best_model_inference_config(model_name,model_version, run_id = None):\n",
    "    print(\" - model_name {} | version {} | run_id: {}\".format(model_name,model_version,run_id))\n",
    "    model = Model(workspace=p.ws,name=model_name, version=model_version)\n",
    "    experiment = Experiment(p.ws,p.experiment_name )\n",
    "    best_run = None\n",
    "    if(run_id is not None):\n",
    "        main_run = PipelineRun(experiment=experiment, run_id=run_id)\n",
    "        best_run = main_run\n",
    "    inference_config, model, best_run = IESMLController.get_best_model_inference_config(p.ws, p.model_folder_name,p.ModelAlias,scoring_script_folder_local=None, current_model=model,run_id_tag=run_id, best_run = best_run)\n",
    "    return inference_config, model, best_run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option B (Model A): ...Deploy ANY model (not only the best promoted model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'your_model_folder_name' # '11_diabetes_model_reg' - Find a model name in Azure ML Studio/Model register or lake_settings.json\n",
    "model_version = 1 # Find a model name in Azure ML Studio/Model register\n",
    "run_id = 'todo_c70-3ef4-470c-9f55-92b33318c8ad'# '9360ac70-3ef4-470c-9f55-92b33318c8ad' # Main pipeline run - Find a model name in Azure ML Studio/Model register\n",
    "\n",
    "inference_config, model, best_run = get_best_model_inference_config(model_name,model_version,run_id)\n",
    "service,api_uri, kv_aks_api_secret= p.deploy_model_as_private_aks_online_endpoint(model,inference_config,overwrite_endpoint=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) `Smoke testing:` TEST ENDPOINT - Score with some test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get testdata, and score it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.connect_to_lake()\n",
    "X_test, y_test, tags = p.get_gold_validate_Xy()\n",
    "caller_id = \"10965d9c-40ca-4e47-9723-5a608a32a0e4\" # Pass an optional tracking ID for the request, parquet file will then have this name\n",
    "\n",
    "df = p.call_webservice(p.ws, X_test,caller_id) # Saves to datalake also\n",
    "#df = p.call_webservice(ws=p.ws, pandas_X_test=X_test.iloc[:1],user_id=caller_id,firstRowOnly=True,save_2_lake_also=False) # If only 1 row, and not saving result to datalake\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END) `SUMMARY - what did the notebook do:DEPLOY & SERVE: Fetched the BEST MODEL, and deploys on AKS`\n",
    "- ESML saves `API_key in Azure keyvault automatically`\n",
    "- ESML auto-config solves 4 common 'errors/things': `correct compute name` and `valid replicas, valid agents, valid auto scaling` in \n",
    "    -  AKS_SETTINGS: [aks_config_dev.json](../settings/project_specific/model/dev_test_prod_override/online/aks_config_dev.json)\n",
    "- Tip 1: You can adjust the number of replicas, and different CPU/memory configuration, or using a different compute target.\n",
    "\n",
    "### Logging: enable in [aks_config_dev.json](../settings/project_specific/model/dev_test_prod_override/online/aks_config_dev.json)\n",
    "You can enable logging with LogAnalytics, with the flags\n",
    "\n",
    "    `enable_app_insights:true`\n",
    "    `collect_model_data:true`\n",
    "\n",
    "### AKS_SETTINGS\n",
    "- Here you can edit AKS settings (performance for DEV, TEST, PROD environments) under PROJECT specific MODEL settings and ONLINE = AKS\n",
    "    -  Link: [aks_config_dev.json](../settings/project_specific/model/dev_test_prod_override/online/aks_config_dev.json)\n",
    "- Note: \n",
    "    - Q: Why is `docker_bridge_cidr` a PUBLIC IP? Isn't this a PRIVATE AKS cluster?\n",
    "    - A: Yes, it is PRIVATE. We don’t use the docker bridge for pod communication, but as Docker is configured as part of the Kubernetes setup, this docker bridge it also gets created as well, so in order to avoid that it picks random unknown CIDR that could collide with any of your existent subnets, we give the option to change it and set it a known range. So the indication for docker bridge is to define any CIDR that doesn’t to Azure, and doesn’t collide with any other subnet. \n",
    "        - Read more: [learn.microsoft.com](https://learn.microsoft.com/en-us/answers/questions/199786/how-to-update-docker-bridge-cidr-for-aks-to-a-diff.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('azure_automl_esml_v144')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4a3f6f829c0fbf992fdd78de6ec4e694e293d154a9b96895f90a426de0ee97e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
