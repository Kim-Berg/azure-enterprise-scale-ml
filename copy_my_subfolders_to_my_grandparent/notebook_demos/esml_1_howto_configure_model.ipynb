{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  },
  "interpreter": {
   "hash": "3fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Enterprise Scale ML (ESML) on Azure - AI Factory\n",
    "- Best Practics Docs about ESML AI Factories:\n",
    "https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/ai-machine-learning-mlops#mlops-at-organizational-scale-ai-factories"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![](../azure-enterprise-scale-ml/esml/images/esml-turnkey-small.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ESML AI Factory: Can I just use the Azure ML SDK directly? Instead of the ESML SDK? \n",
    "- Yes, You can bypass ESML SDK 100%  (the 4th ingredience) and only take advantage of the 3 other ingredients: part: 1,2,3\n",
    "    - part 1) `Azure services glued together securely` (ARM / Provisioing / Networking / Infra)\n",
    "    - part 2) `Azure Devops template, for MLOps` (BUILD and RELEASE pipelines / Networking / Security & Glue) \n",
    "    - part 3) `The enterprise datalake design` (ADLS Gen2 storage account, with a folder structure)\n",
    "    \n",
    "- That said, most `accelerator power` is when you use the `EMSL SDK`, some benefits listed below (look at README feature list for all)\n",
    "    - `4 out of the 7 steps/pipelines of a ML application`: There is `always at least 6 steps you need to create`, step 7 is optional.\n",
    "    - ESML gives you 4 of these automatically. Not the asterix (*) ones, but the `gold ones` (3,4,5a,7)\n",
    "        - *1) Ingest from source\n",
    "            - Azure Data Factory: This is too specific for EMSL. A COPY Activity from your source (DW/Database) to the IN-folder in ADLS Gen2, Datalake)\n",
    "        - *2) FeatureEngineering \"Bronze2Gold\"\n",
    "            - Azure ML Pipeline: Too specific for ESML. You need yo create your own Azure ML Pipleine)\n",
    "        - `3) TrainModel` (AutoML pipeline - you can also create your own manual Training Azure ML Pipeline)\n",
    "        - `4) CompareScoringDrift & DataDrift` - Should be promote & Deploy the newly trained model? Needed to refit model to real world changes.\n",
    "        - `5a) Deploy AKS Scoring endpoint - Online/Batch (Only up to 5min REST call for BATCH)`\n",
    "        - *5b) Deploy Scoring endpoint - Batch\n",
    "            - Azure ML Pipeline: You need to create an AML batch pipline if `5a`  ONLINE/BATCH does not work..limited to 5min BATCHes...you can always to `5min looping`)\n",
    "        - *6) `ConsumeScoring` & WriteBack (Azure Data Factory: This is too specific for EMSL. \n",
    "            - But ESML has already written the data to the Datalake, you you jsut need a simple COPY ACTIVITY from ADLS Gen2, to your `Target/DW/Database`)\n",
    "            - Hence, the `ConsumeScoring` ESML also provide - where you can `filter` scored data, on `datetime`, or `caller_id`, etc\n",
    "        - `7)ShareBackPipeline` (Write back refined project SILVER data, to MASTER datalake, for others to use\n",
    "            - ¤¤= This STEP/Pipeline, is of course NOT important if you don't need refined data, reused in your organization.\n",
    "\n",
    "## - If I only want to REFINE DATA for a Power BI report? \n",
    "`Besides the 6-step \"ML application\" process` above ↑ The ESML SDK gives a data engieer / Data scientists / Power BI ninja, also these benefits, on a `DETAILED level`\n",
    "- `Datalake aware`: ESML knows the lake structure. You never need to rememeber any paths. Just work with BRONZE, SILVER, GOLD concept + ML Concepts (TRAIN vs INFERENCE)\n",
    "- `Datasets`: Autoregisters Azure ML Datasets in correct workspace, with naming convention + tags of scoring, split, versioning, and a UI to browse data\n",
    "    - Datasets does not need to be used for Machine learning. Seet this as a `feature store` for your project. The `model_folder` in the lake, can be `Power BI report datasets`\n",
    "    - If you just want to `REFINE data for a Power BI report`, you can leverage the same BRONZE,SILVER, GOLD concept and the `AutoLake`\n",
    "- `Deploy application/code` across 3 environments/3 subscriptions: Dev,Test, Prod\n",
    "    - 1-liner DEPLOY a model to online AKS webservice in DEV or to TEST or PROD, but anything can be deployed...\n",
    "    - What we deploy, can be a WebApplication, does not need to be a ML-model in the AKS Webservice.\n",
    "- `Governance`: ENTERPRISE SPECIFIC settings, global for all projects, and `PROJECT SPECIFIC` settings\n",
    "    - `DEV, TEST, PROD SETTINGS`: Settings for: Performance & Compute (Train, Inference), Training time, \n",
    "    - `DEV,TEST,PROD PROJECTS `: A project has a `set of Azure PaaS services` that can talk, due to ESML SDK glue:\n",
    "        - `Azure Databricks` -> (can talk & read/write) to the `Datalake`, due to the ESML mount/mappings & built in security/Networking\n",
    "        - `Azure Databricks` -> (can talk & read/write) to `Azure ML Studio` (and vice versa) due to the ESML settings & built security & built in security/Networking\n",
    "        - `Azure Datafactory` -> (can talk) to `Datalake` and `Azure Databricks` and `Azure ML Studio` \n",
    "            - Due to ESML built in security/Networking (also bootstrap piplines for `WriteBackToMaster`)\n",
    "        - `Azure Devops` can be used due to security/Networking\n",
    "        - `Dev->Test->Prod`: `DEV` services can only talk to DEV (Networking/Security), and the neighbour TEST, but never jump `DEV` to talk or deploy directly to `PROD` services\n",
    "- `Security`: Networking & Identity & Security (ESML SDK knows how to speak with vNets and Private link, and Keyvaults)\n",
    "    - `Dev->Test->Prod`: `DEV` services can only talk to DEV (Networking/Security), and the neighbour TEST, but never jump `DEV` to talk or deploy directly to `PROD` services\n",
    "    - `Private Link (Azure backbone)` is the default EMSL networking setup, when services talk to each other.\n",
    "        - Exceptions of private link: Sometimes Azure DAtabricks is only vNet injected. (Azure Devops build agent is on same vNet only)\n",
    "-  (Plus the ML parts in detail)\n",
    "    - `ML`: Test_Set scoring with a 1-liner, registers this as TAGS on GOLD_TEST set in Azure ML Studio, and TAGS on best MODEL at run. (`once and only once` to calcuate scoring)\n",
    "    - `Azure ML pipeline: Train`: AutoML training with a 2-liner\n",
    "    - `MLOps pipline`: All 6 steps `for FREE` when using ESML, including `SCORING DRIFT` and Dev,Test,Prod aware when comparing `SCORING DRIFT`\n",
    "    - `MLOps:Scoring drift` across 3 environments, a 1-liner, `promotes` the model to correct ENVIRONMENT (dev,test, prod) if `better` (gets promoted)\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# ...So...enough info....lets START CONFIGURE! "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Howto - configure `ESML Python SDK` for a MODEL? \n",
    "- ESML comes with 2 DEMO models: 1 Classification(Titanic) and 1 Regression (Diabetes) `TASK_TYPE` \n",
    "    - DATA: You have the TITANIC and DIABETES MODEL folders with data in ESML GIT, or in your local folder: `\\azure-enterprise-scale-ml\\copy_my_subfolders_to_my_grandparent\\demo_data\\`\n",
    "    - 1) First, we need to configure the DATA you want to use for MODEL, that is the ESML AutoLake\n",
    "    - `*`2) Then, optinally adjust our definition of SCORING_DRIFT - scoring `WEIGHTS` on `regression` or `classification` TASK_TYPE\n",
    "\n",
    "`*Optional`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1) CONFIGURE MODEL & DATA - `LAKE_SETTINGS`\n",
    "- Mandatory"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![](../azure-enterprise-scale-ml/esml/images/01_setup_model_1.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## LAKE_SETTINGS - More info\n",
    "- 1) lake_settings.json: Point at the \"model_folder\" and filter your \"dataset_folders\"\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1) lake_settings\n",
    "- Here you can see an easy way to have multiple models, and that `the \"_\" prefix has a model \"inactive\"`\n",
    "- \n",
    "- \n",
    "![](../azure-enterprise-scale-ml/esml/images/01_setup_model_2.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2) OPTIONAL - model_settings\n",
    "- Purpose: For SCORING-DRIFT to know what metrics to use when COMPARING `compare_metrics` that YOU control, and can put `WEIGHTs` on also.\n",
    "- See also the `\"docs1\"`, `\"docs2\"`,`\"docs3\"` text in image\n",
    "- All else, you can set to 0.0 to have no `WEIGHTS` when comparing scoring for model A and B, to see if we want ot promote model A\n",
    "- ![](../azure-enterprise-scale-ml/esml/images/01_setup_model_3.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3) DATA: CONFIGURE `Date_Folder for DATA to use` (demo data is already configured)\n",
    "- Per `ENVIRONMENT (dev,test,prod)` and per `TRAINING` and `INFERENCE` you can have different data, you can also `choose what MODEL_VERSION to score with`, at INFERENCE\n",
    "- These .JSON files can be overridden by ESMLProject Constructor, and/or by putting these file in the ESML AutoLake's `active` folder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- ![](../azure-enterprise-scale-ml/esml/images/01_setup_model_4.png)\n",
    "- ![](../azure-enterprise-scale-ml/esml/images/01_setup_model_5.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## HIGHLY Optional: Play around different ways to \"Override\" ESMLProject ACTIVE settings\n",
    "- You can bypass ESML SDK 100% - the 4th ingredience  - and only take advantage of the 3 other ingrediences: 1,2,3\n",
    "    - 1) `Azure services glued together securely` (ARM / Provisioing / Networking / Infra)\n",
    "    - 2) `Azure Devops template, for MLOps` (BUILD and RELEASE pipelines / Networking / Security & Glue) \n",
    "    - 3) `The enterprise datalake design` (ADLS Gen2 storage account, with a folder structure)\n",
    "    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Howto override above JSON-files - \"Active\" `date_folder` to TRAIN or INFERENCE and `inference_model_version`? \n",
    "- A) `CONSTRUCTOR / Python commandline override:` These .JSON files can be overridden by ESMLProject Constructor\n",
    "    - `p = ESMLProject(param_esml_env,param_inference_model_version,param_scoring_folder_date,param_train_in_folder_date)`\n",
    "    - ESML will then overwrite LOCAL json-files, and never look into the DataLake `active` folders\n",
    "    - `Useful scenario:` Send as `ArgParse` from `Azure Devops - MLOps pipeline` after `code_change`, to set the ESML evnironment (dev,test,prod)\n",
    "        - MLOps `New Code` trigger\n",
    "        - Note: This is excately what the ESML MLOps template does: `p = ESMLProject.get_project_from_env_command_line()`\n",
    "- B) `LAKE override:` You can also put these .JSON files in the ESML AutoLake's `active` folder \n",
    "    - EMSL will 1st read from lake, and overwrite LOCAL .json files (See images `For TRAINING` and `For INFERENCE` below)\n",
    "    - `Useful scenario:` Write these files with `Azure Datafactory` after ingestion pipeline\n",
    "        - MLOps `New data` trigger\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### B) Override via LAKE files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## For TRAINING (in_folder to train on)\n",
    "- ![](../azure-enterprise-scale-ml/esml/images/01_setup_model_7.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## For INFERENCE (model_version, date_folder_to_score)\n",
    "- ![](../azure-enterprise-scale-ml/esml/images/01_setup_model_8.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# TROUBLE SHOOTING!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Q: p.init()  gives error, cannot find Dataset files in datalake? \n",
    " - `StreamAccessException was caused by NotFoundException.`\n",
    "## A: \n",
    "- The usual case is that the \"Date_Folder\" (DateTime) in active/active_in_folder.json settings is wrong (they dont point at correct data_folder in datalake)\n",
    "- Another thing, can be that you have `p.inference_mode=True` is you want to TRAIN model....it should be False when training, for it to look in the `TRAIN lake-folder structure`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "....Look at this path with Azure Data explorer, to see that you have data...that mathes the PATH in the Error message....yes, there is a path there somewhere, along with all the text : )\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- ![](../azure-enterprise-scale-ml/esml/images/01_setup_model_6.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}