{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  },
  "interpreter": {
   "hash": "3fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ESML - accelerator: Quick DEMO\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import repackage\r\n",
    "repackage.add(\"../azure-enterprise-scale-ml/esml/common/\")\r\n",
    "from esml import ESMLDataset, ESMLProject\r\n",
    "\r\n",
    "p = ESMLProject() # Will search in ROOT for your copied SETTINGS folder '../../../settings', you should copy template settings from '../settings'\r\n",
    "p.active_model = 11\r\n",
    "p.inference_mode = False\r\n",
    "p.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "unregister_all_datasets=False\r\n",
    "if(unregister_all_datasets):\r\n",
    "    p.unregister_all_datasets(p.ws) # For DEMO purpose"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "ws = Workspace.get(name = p.workspace_name,subscription_id = p.subscription_id,resource_group = p.resource_group,auth=auth)\n",
    "ws.write_config(path=\".\", file_name=\"../../ws_config.json\")\n",
    "\n",
    "ws = Workspace.from_config(\"../ws_config.json\") # Reads config.json "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2) ESML will Automap and Autoregister Azure ML Datasets - IN, SILVER, BRONZE, GOLD\n",
    "- `Automap` and `Autoregister` Azure ML Datasets as: `IN, SILVER, BRONZE, GOLD`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import Workspace\r\n",
    "ws, config_name = p.authenticate_workspace_and_write_config()\r\n",
    "ws = p.get_workspace_from_config()\r\n",
    "ws.name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Are we in R&D state (no dataset versioning) = {}\".format(p.rnd))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "datastore = p.init(ws)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3) IN->`BRONZE->SILVER`->Gold\n",
    "- Create dataset from PANDAS - Save to SILVER"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd \r\n",
    "ds = p.DatasetByName(\"ds01_diabetes\")\r\n",
    "df = ds.Bronze.to_pandas_dataframe()\r\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) BRONZE-SILVER (EDIT rows & SAVE)\n",
    "- Test change rows, same structure = new version (and new file added)\n",
    "- Note: not earlier files in folder are removed. They are needed for other \"versions\". \n",
    "- Expected: For 3 files: New version, 997 rows: 2 older files=627 + 1 new file=370\n",
    "- Expected (if we delete OLD files): New version, with less rows. 370 instead of 997"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_filtered = df[df.AGE > 0.015]\r\n",
    "print(df.shape[0], df_filtered.shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3a) Save `SILVER` ds01_diabetes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aml_silver = p.save_silver(p.DatasetByName(\"ds01_diabetes\"),df_filtered)\r\n",
    "aml_silver.name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### COMPARE `BRONZE vs SILVER`\n",
    "- Compare and validate the feature engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds01 = p.DatasetByName(\"ds01_diabetes\")\r\n",
    "bronze_rows = ds01.Bronze.to_pandas_dataframe().shape[0]\r\n",
    "silver_rows = ds01.Silver.to_pandas_dataframe().shape[0]\r\n",
    "\r\n",
    "print(\"Bronze: {}\".format(bronze_rows)) # Expected 442 rows\r\n",
    "print(\"Silver: {}\".format(silver_rows)) # Expected 185 rows (filtered)\r\n",
    "\r\n",
    "assert bronze_rows == 442,\"BRONZE Should have 442 rows to start with, but is {}\".format(bronze_rows)\r\n",
    "assert silver_rows == 185,\"SILVER should have 185 after filtering, but is {}\".format(silver_rows)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3b) Save  `BRONZE â†’  SILVER` ds02_other"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_edited = p.DatasetByName(\"ds02_other\").Silver.to_pandas_dataframe()\r\n",
    "ds02_silver = p.save_silver(p.DatasetByName(\"ds02_other\"),df_edited)\r\n",
    "ds02_silver.name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3c) Merge all `SILVERS -> then save GOLD`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_01 = ds01.Silver.to_pandas_dataframe()\r\n",
    "df_02 = ds02_silver.to_pandas_dataframe()\r\n",
    "df_gold1_join = df_01.join(df_02) # left join -> NULL on df_02\r\n",
    "print(\"Diabetes shape: \", df_01.shape)\r\n",
    "print(df_gold1_join.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save `GOLD` v1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p.rnd=False # Allow versioning on DATASETS, to have lineage"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds_gold_v1 = p.save_gold(df_gold1_join)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3c) Ops! \"faulty\" GOLD - too many features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(p.Gold.to_pandas_dataframe().shape) # 19 features...I want 11"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Are we in RnD phase? Or do we have 'versioning on datasets=ON'\")\r\n",
    "print(\"RnD phase = {}\".format(p.rnd))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save `GOLD` v2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Lets just go with features from ds01\r\n",
    "ds_gold_v1 = p.save_gold(df_01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get `GOLD` by version"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gold_1 = p.get_gold_version(1)\r\n",
    "gold_1.to_pandas_dataframe().shape # (185, 19)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gold_2 = p.get_gold_version(2)\r\n",
    "gold_2.to_pandas_dataframe().shape # (185, 11)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p.Gold.to_pandas_dataframe().shape # Latest version (185, 11)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_01_filtered = df_01[df_01.AGE > 0.03807]\r\n",
    "ds_gold_v1 = p.save_gold(df_01_filtered)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gold_2 = p.get_gold_version(3) # sliced, from latest version\r\n",
    "gold_2.to_pandas_dataframe().shape # (113, 11)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TRAIN - `AutoMLFactory + ComputeFactory`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from baselayer_azure_ml import AutoMLFactory, ComputeFactory"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p.dev_test_prod = \"test\"\r\n",
    "print(\"what environment are we targeting? =  {}\".format(p.dev_test_prod)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "automl_performance_config = p.get_automl_performance_config()\r\n",
    "automl_performance_config"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p.dev_test_prod = \"dev\"\r\n",
    "automl_performance_config = p.get_automl_performance_config()\r\n",
    "automl_performance_config"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get `COMPUTE` for current `ENVIRONMENT`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aml_compute = p.get_training_aml_compute(ws)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# `TRAIN` model -> See other notebook `esml_howto_2_train.ipynb`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.train.automl import AutoMLConfig\r\n",
    "from baselayer_azure_ml import azure_metric_regression\r\n",
    "\r\n",
    "label = p.active_model[\"label\"]\r\n",
    "train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6,label) # Auto-registerin AZURE (M03_GOLD_TRAIN | M03_GOLD_VALIDATE | M03_GOLD_TEST) # Alt: train,testv= p.Gold.random_split(percentage=0.8, seed=23)\r\n",
    "automl_config = AutoMLConfig(task = 'regression',\r\n",
    "                             primary_metric = azure_metric_regression.MAE,\r\n",
    "                             compute_target = aml_compute,\r\n",
    "                             training_data = p.GoldTrain, # is 'train_6' pandas dataframe, but as an Azure ML Dataset\r\n",
    "                             label_column_name = label,\r\n",
    "                             experiment_exit_score = '0.308', # DEMO purpose\r\n",
    "                             **automl_performance_config\r\n",
    "                            )\r\n",
    "\r\n",
    "via_pipeline = False\r\n",
    "best_run, fitted_model, experiment = AutoMLFactory(p).train_pipeline(automl_config) if via_pipeline else AutoMLFactory(p).train_as_run(automl_config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# END"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ESML - accelerator\n",
    "\n",
    "## PROJECT + DATA CONCEPTS + ENTERPRISE Datalake Design + DEV->PROD MLOps\n",
    "- `1)ESML Project`: The ONLY thing you need to remember is your `Project number` (and `BRONZE, SILVER, GOLD` concept )\n",
    "    - ProjectNo=4 have a list of all your datasets as ESMLDatasets. (Well you need to provide names for them also: \"mydata01\", \"mydata02\" - but thats it)\n",
    "- `2)Lakedesign & Roles`: Bronze, silver, gold + IN and date folders\n",
    "    - Benefits: Physical datalake design!  onnected to Azure ML Workspace, with autoregistration of `Azure ML Datasets`\n",
    "    - `Role 1`: `Data ingestion team` only need to care about 1 thing - onboard data to `IN-folder`, in .CSV format\n",
    "        - `Auto parquet-conversion` from `IN` folder (.CSV) to `OUT`/BRONZE/bronze.PARQUET \n",
    "    - `Role 2`: `Data scientists` only need to care about 3 things (R/W): `BRONZE, SILVER, GOLD` datasets, all in .PARQUET format\n",
    "    - How? The ESML project will `Automap` and `Autoregister` Azure ML Datasets - `IN, SILVER, BRONZE, GOLD`\n",
    "- `2a) R&D  VS Production phase`: \"Latest data\" VS versioning on Datasets and datefolders  \n",
    "    - Benefits \"R&D mode\": Faster RnD phase to onboard and refresh data easy. Also fast \"flip-switch\" to production\n",
    "    - How? `ESMLDataset is context self aware` - knows when it is used in TRAIN or INFERENCE pipeline\n",
    "- `2b) TRAIN vs INFERENCE` versions</u> `Reuse (Bronze->Silver->Gold) pipepline`, for both TRAIN preprocessing, and INFERENCE \n",
    "    - Benefits: Inference with different MODEL version, on data from the same day/time, (to compare scoring etc)\n",
    "    - How? ESMLDataset have context self awareness, and `knows WHERE and HOW to load/save data`\n",
    "- `2c) BATCH CONFIG`: Turn on/off features on ALL datasets\n",
    "    - Accelerate setup: `Datadrift, Time series traits, Smart noise, etc`\n",
    "    - Share refined data back to its \"origin/non-projectbased structure\" easy: \n",
    "        - ESMLProject.ShareBack(ds.Silver)\n",
    "    - How? ESMProject controls all ESMDatasets, in a uniform way\n",
    "## ENTERPRISE Deployment of Models & Governance - MLOps  at scale\n",
    "- `3) DEV->TEST-PROD` (configs, compute, performance)\n",
    "    - ESML has config for 3 environemnts: Easy DEPLOY model across subscriptions and Azure ML Studio workspaces \n",
    "        - Save costs & time: \n",
    "            - `DEV` has cheaper compute performance for TRAIN and INFERENCE (batch, AKS)\n",
    "            - `DEV` has Quick-debug ML training (fast training...VS good scoring in TEST and PROD)\n",
    "        - How? ESML `AutoMLFactory` and `ComputeFactory`\n",
    "         \n",
    "\n",
    "### Q&A:\n",
    "- Q: Is ESML Machine learning specific? If I only want to refine some data...for integration, or report? \n",
    "- A: You can use this for just data refinement also: `Bronze->Silver->Gold` refinement.\n",
    "    - Benefits: Enterprise security, Read/write to datalake, easy to share refined data. \n",
    "    - Benefits: The tooling \"glued togehter\": Azure datafactory +  Azure Databricks (and Azure ML Studio pipelines if needed)\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p.dev_test_prod"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from baselayer_azure_ml import AutoMLFactory\r\n",
    "target_env = p.dev_test_prod #\"dev\", test, prod  = Target environment. Does Model A score better than Model B?\r\n",
    "print(\"Example: If new model scores better in DEV, we can promote this to TEST\")\r\n",
    "\r\n",
    "promote, m1_name, r1_id, m2_name, r2_run_id = AutoMLFactory(p).compare_scoring_current_vs_new_model(target_env)\r\n",
    "\r\n",
    "print(\"Promote model?  {}\".format(promote))\r\n",
    "print(\"New Model: {} in environment {}\".format(m1_name, p.dev_test_prod))\r\n",
    "print(\"Existing Model: {} in environment {}\".format(m2_name,target_env))\r\n",
    "\r\n",
    "if (promote and p.dev_test_prod == target_env):# Can only register a model in same workspace (test->test) - need to retrain if going from dev->test\r\n",
    "    AutoMLFactory(p).register_active_model(target_env)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inference_config, model, best_run = p.get_active_model_inference_config(ws) #  AutoML support \r\n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_test, y_test, tags = p.get_gold_validate_Xy() # Get the X_test data, ESML knows the SPLIT and LABEL already (due to training)\r\n",
    "print(tags)\r\n",
    "\r\n",
    "df = p.call_webservice(p.ws, X_test,\"my_caller_id_tracker_guid\") # Auto-fetch key from keyvault, and calls the webservice\r\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}