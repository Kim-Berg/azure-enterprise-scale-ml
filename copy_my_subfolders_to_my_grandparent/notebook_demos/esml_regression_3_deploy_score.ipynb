{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  },
  "interpreter": {
   "hash": "3fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1) Init ESML "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../azure-enterprise-scale-ml/esml/common/\"))  # NOQA: E402\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "from azureml.core import Workspace\n",
    "\n",
    "p = ESMLProject() # Makes it \"environment aware (dev,test,prod)\", and \"configuration aware\"\n",
    "ws = p.get_workspace_from_config()\n",
    "p.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregister_all_datasets=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(unregister_all_datasets):\n",
    "    p.unregister_all_datasets(ws) # For DEMO purpose\n",
    "\n",
    "p.init(ws) \n",
    "p.dev_test_prod = \"dev\"\n",
    "#Note: This happens in the INIT() method of DriverAPI/CallingAppliation...not loading for every Scoring"
   ]
  },
  {
   "source": [
    "# 2) Test an `existing` Model webservice (AKS)?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2a) Lets simulate INFERENCE: data arives from CLIENT to a `DriverAPI` that itself will call `this ModelAPI` (AKS)\n",
    "Note: `Step 1 and 2 are out of scope` of from the MACHINE LEARNING solution (and ESML), other than...\n",
    " - `ESML` being the creator of AML pipeline - `Bronze_2_Gold` that you can reuse\n",
    " - `ESML lakedesign`, that should be used, if INFERENCE are to be stored/cached in the lake\n",
    "\n",
    "NOW - the scenario: \n",
    "\n",
    "- DriverAPI will:\n",
    "\n",
    "    - 1)Fetch missing datasources from different systems, to get all data sources ds01, ds02,ds03 & SAVE to INFERENCE/IN folder in the datalake\n",
    "        - Use the `ESML` lakedesign:  IF `inference_model_version=1` in `settings/project_specific/lake_settings.json` then...\n",
    "        - `ESML` will switch to write at `INFERENCE/v1/ds01/IN/2020/01/01` folder \n",
    "    - 2)Call `Bronze_2_Gold` batch pipeline (AML) - same pipeline that was used for training: `IN->Bronze->Silver->Gold`, except...\n",
    "        - `Bronze_2_Gold` pipeline will read from IN folder, but configured for \"INFERENCE\", read/write to `\"mirror\"` place in the datalake, that will `CACHE` online predicted results\n",
    "        - (LABEL values are missing of course)\n",
    "    - 3) `DriverAPI calls ModelAPI` (This AKS webservuce) with data to score -> `X_text`\n",
    "\n",
    "- `ESML` ModelAPI will:\n",
    "    - 4) `Score` the data, and return results, also `save the results to the datalake`\n",
    "        - if `p.rnd=True` nothing is stored.\n",
    "    - 5) `Connect the scored data` to a caller, and the individual scores to a identity (user/machine)\n",
    "        - GLOBALLY & ESML Managed: The scoring file gets a caller_id. \n",
    "            - You: Need to pass the called-guid as a parameter. \n",
    "                - Alternatively, you can have a column in the dataframe called `esml_caller_id_string`, and ESML will use that.\n",
    "        - LOCALLY: The rows in the dataframe has an identity. \n",
    "            - You: Here you need to have a column in the dataframe, such as `user_id`, to be able to connect each row to a scoring.\n",
    "\n",
    "\n",
    "Step 1 and 2 are out of scope of from the MACHINE LEARNING solution  \n",
    "We START this notebooke at step 3 - we have `X_test` in `GOLD_Validate` status "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "now = dt.datetime.now()\n",
    "folder = now.strftime('%Y_%m_%d') \n",
    "print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(unregister_all_datasets): # Create a GOLD dataset, and SPLIT it\n",
    "    df_01 = p.DatasetByName(\"ds01_diabetes\").Silver.to_pandas_dataframe()\n",
    "    ds_gold_v1 = p.save_gold(df_01)\n",
    "\n",
    "    label = \"Y\"\n",
    "    train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Bronze_2_Gold done, we can fetch X_test\n",
    "X_test, y_test, tags = p.get_gold_validate_Xy() # Version is default latest\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "source": [
    "### 2b) Call onlin ModelAPI - score 1 row (alt 1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "#3) `DriverAPI calls ModelAPI`\n",
    "\n",
    "keyvault = p.ws.get_default_keyvault()\n",
    "api_url = keyvault.get_secret(name=\"esml-dev-p02-m03-api\")\n",
    "api_key = keyvault.get_secret(name=\"esml-dev-p02-m03-apisecret\")  # esml-dev-p02-m03-apisecret\n",
    "\n",
    "df = ESMLProject.call_webservice_own_url(X_test, api_url,api_key) # rest call. STATIC method - simulate \"we dont need ESML for this\" - just an URL and KEY from DriverAPI\n",
    "df.head() # Print scoring"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2b) Call online ModelAPI - score all rows (alt 2) - `via ESML wrapper`\n",
    "- ESML benefits: Has built in `logic` to save scored_results, to unique folders during the day.\n",
    "- Note: We can also save a GUID/ID, `to see which CALLER/User-Guid the scoring is about` \n",
    "    - We can have a User_id_GUID as a \"feature/column\" in X_test, or as a parameter in the call"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.inferenceModelVersion=1\n",
    "print(p.ScoredPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caller_user_id = '81965d9c-40ca-4e47-9723-5a608a32a0e4' # Connect the scoring to a caller/user, globally for all rows\n",
    "\n",
    "df = p.call_webservice(p.ws, X_test, caller_user_id, False) # Auto-fetch key from keyvault, 1stRowOnlye=False\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "# 3) How to GET SCORE data? how to FILTER scored results?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, tags = p.get_gold_validate_Xy()\n",
    "caller_user_id = '91965d9c-40ca-4e47-9723-5a608a32a0e4' # Connect the scoring to a caller/user, globally for all rows\n",
    "\n",
    "df = p.call_webservice(p.ws, X_test, caller_user_id, False) # Auto-fetch key from keyvault, 1stRowOnlye=False\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "now = dt.datetime.now()\n",
    "date_filter = now.strftime('%Y_%m_%d') \n",
    "print(date_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list, df_all = p.get_scored(date_filter, \"10\",'81965d9c-40ca-4e47-9723-5a608a32a0e4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = p.get_scored('last_month')\n",
    "ds_list1, df_all1 = p.get_scored(date_filter, \"1\",'81965d9c-40ca-4e47-9723-5a608a32a0e4')\n",
    "print(\"Datasets found in filter\", len(ds_list1))\n",
    "print(\"Example: How many rows in 1st dataset? \", ds_list1[0].to_pandas_dataframe().shape[0])\n",
    "print(\"All rows\", df_all1.shape[0])\n",
    "\n",
    "df_all1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list, df_all = p.get_scored(date_filter, \"1\")\n",
    "print(\"Datasets found in filter\", len(ds_list))\n",
    "print(\"Example: How many rows in 1st dataset? \", ds_list[0].to_pandas_dataframe().shape[0])\n",
    "print(\"All rows\", df_all.shape[0])"
   ]
  },
  {
   "source": [
    " ** Train model & register ....this happended already in another notebook/MLops pipline step\n",
    "> model = p.register_active_model()  \n",
    "> print(model.name, model.description, model.version)  \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 3a) ESML `Deploy a new ONLINE` webservice (AKS)\n",
    "- Deploy \"offline\" from old `AutoML run` for `DEV` environment\n",
    "- To â†’  `DEV`, `TEST` or `PROD` environment\n",
    "- ESML saves `API_key in Azure keyvault automatically`\n",
    "- ESML auto-config solves 4 common 'errors/things': `correct compute name` and `valid replicas, valid agents, valid auto scaling`\n",
    "    - Tip: You can adjust the number of replicas, and different CPU/memory configuration, or using a different compute target."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config, model, best_run = p.get_active_model_inference_config(ws) #  AutoML support \n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config, True) # overwrite_endpoint=True"
   ]
  },
  {
   "source": [
    "# Test the NEW AKS WebService"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, tags = p.get_gold_validate_Xy() # Version is default latest\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = p.call_webservice(p.ws, X_test) # Auto-fetch key from keyvault, 1stRowOnlye=False  |   p.call_webservice(p.ws, X_test, caller_user_id, False)\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "# Code to `embed in YOUR DriverApi` - to call this webservice `without ESML`\n",
    "- `NB!` This will `NOT cache` the results automatically, since not going via the ESML SDK. You need to save the scoring yourself ( if this is needed)\n",
    "    - ESML benefits: Has built in `logic` to save scored_results, to unique folders during the day.\n",
    "            # Note: We can also save a GUID/ID, for which CALLER/User-Guid it is about. We can have a User_id_GUID as a \"feature/column\" in X_test, or as a parameter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_webservice_code(rows, api_uri,api_key, allowSelfSigned=True):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowSelfSigned and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "    X_test_json_works = json.dumps({'data': rows.to_dict(orient='records')})\n",
    "\n",
    "    headers = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + api_key}\n",
    "    resp = requests.post(api_uri, X_test_json_works , headers=headers) \n",
    "\n",
    "    # Here you can pass forward the response, save it to the datalake, or as below return a PANDAS dataframe\n",
    "    res_dict = json.loads(resp.text)\n",
    "    res_dict_ast = ast.literal_eval(res_dict)\n",
    "    return pd.read_json(res_dict) # to pandas"
   ]
  },
  {
   "source": [
    "## 3b) ESML `Deploy BATCH` pipeline\n",
    "- Deploy same model \"offline / previous\" `AutoML Run` for `DEV` environment\n",
    "- To â†’  `DEV`, `TEST` or `PROD` environment\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 5a alt2) If not using AutoML - you need to manuallt create `environemnt + entryscript + inference config`\n",
    "https://github.com/Azure/MachineLearningNotebooks/blob/bda592a236eaf2dbc54b394e1fa1b539e0297908/how-to-use-azureml/deployment/production-deploy-to-aks/production-deploy-to-aks.ipynb"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ENVIRONMENT - If not AUTOML\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "conda_deps = CondaDependencies.create(conda_packages=['numpy','scikit-learn==0.19.1','scipy'], pip_packages=['azureml-defaults', 'inference-schema'])\n",
    "myenv = Environment(name='myenv')\n",
    "myenv.python.conda_dependencies = conda_deps"
   ]
  },
  {
   "source": [
    "%%writefile score.py\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
    "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
    "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_regression_model.pkl')\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# note you can pass in multiple rows for scoring\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        data = numpy.array(data)\n",
    "        result = model.predict(data)\n",
    "        # you can return any data type as long as it is JSON-serializable\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "inf_config = InferenceConfig(entry_script='score.py', environment=myenv)"
   ]
  },
  {
   "source": [
    "# OTHER - What more can you retrieve from AutoMLFactory and ESMLProject?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselayer_azure_ml import AutoMLFactory\n",
    "from baselayer_azure_ml import ComputeFactory\n",
    "\n",
    "target_model, target_best_run_id = AutoMLFactory().get_latest_model(ws)\n",
    "print(target_model.name)\n",
    "print(target_best_run_id)\n",
    "\n",
    "run, exp = p.get_active_model_run_and_experiment()\n",
    "inference_config = p.get_active_model_inference_config()\n",
    "print(run)\n",
    "print(exp.name)"
   ]
  }
 ]
}