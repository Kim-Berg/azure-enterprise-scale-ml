{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESML: Customize Scoring script: \n",
    "## Redeploy model  on AKS, adding predict_proba to scoring_script (based on AutoML generated)\n",
    "- 1) `AutoMap datalake` & init ESML project\n",
    "- 2) `Get earlier trained model`\n",
    "- 3) `Get AutoML genereated scoring script`\n",
    "    - This DEMO notebook, uses TITANIC, to add predict_proba.\n",
    "    - Copy from here: `\\azure-enterprise-scale-ml\\copy_my_subfolders_to_my_grandparent\\settings\\project_specific\\model\\dev_test_prod\\train\\automl\\scoring_file_dev_M01_titanic.py`\n",
    "    - Paste to YOUR settings folder: `\\settings\\project_specific\\model\\dev_test_prod\\train\\automl\\scoring_file_dev_M01_titanic.py`\n",
    "- 4) `Customize scoring script & redeploy`\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "######  NB! This,InteractiveLoginAuthentication, is only needed to run 1st time, then when ws_config is written, use later CELL in notebook, that just reads that file\n",
    "import repackage\n",
    "repackage.add(\"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "\n",
    "p = ESMLProject()\n",
    "p.dev_test_prod=\"dev\"\n",
    "auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "ws, config_name = p.authenticate_workspace_and_write_config(auth)\n",
    "######  NB!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregister_all_datasets=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import repackage\n",
    "repackage.add(\"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "\n",
    "p = ESMLProject() # Will search in ROOT for your copied SETTINGS folder '../../../settings', you should copy template settings from '../settings'\n",
    "p.inference_mode = False # We want \"TRAIN\" mode\n",
    "p.ws = p.get_workspace_from_config() #2) Load DEV or TEST or PROD Azure ML Studio workspace\n",
    "\n",
    "if(unregister_all_datasets):\n",
    "    p.unregister_all_datasets(ws) # For DEMO purpose\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inference version: 1\n\n - ds01_titanic\nprojects/project002/01_titanic_model_clas/train/ds01_titanic/in/dev/2021/01/01/\nprojects/project002/01_titanic_model_clas/train/ds01_titanic/out/bronze/dev/\nprojects/project002/01_titanic_model_clas/train/ds01_titanic/out/silver/dev/\nprojects/project002/01_titanic_model_clas/inference/1/ds01_titanic/in/dev/2021/01/01/\n \n\nTraining GOLD\nprojects/project002/01_titanic_model_clas/train/gold/dev/\n \n\nA)INFERENCE ONLINE: GOLD to score (example if realtime - today)\nprojects/project002/01_titanic_model_clas/inference/1/gold/dev/2021_06_16/066b4fd80ee746e1b3e7a4a6e0300ba5/\n \n\nA)INFERENCE ONLINE: GOLD scored (example if realtime today)\nprojects/project002/01_titanic_model_clas/inference/1/scored/dev/2021_06_16/066b4fd80ee746e1b3e7a4a6e0300ba5/\n \n\nB)INFERENCE BATCH: GOLD to score (example batch, datetime from config)\nprojects/project002/01_titanic_model_clas/inference/1/gold/dev/2021_01_01/3ed03414d8444f40a764cd1a8f311f90/\n \n\nB)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\nprojects/project002/01_titanic_model_clas/inference/1/scored/dev/2021_01_01/3ed03414d8444f40a764cd1a8f311f90/\n \n\nC) INFERENCE BATCH (SCENARIO 2): TODAY I scored data from X days AGO  (second datefolder from config - X days ago)\nprojects/project002/01_titanic_model_clas/inference/1/gold/dev/2021_01_01/3ed03414d8444f40a764cd1a8f311f90/2021_01_01/\nprojects/project002/01_titanic_model_clas/inference/1/scored/dev/2021_01_01/3ed03414d8444f40a764cd1a8f311f90/2021_01_01/\n \n\nENVIRONMENT - DEV, TEST, or PROD?\nACTIVE ENVIRONMENT = dev\nACTIVE subscription = ca0a8c40-b06a-4e4e-8434-63c03a1dee34\n- MSFT-WEU-EAP_PROJECT02_AI-DEV-RG\n- msft-weu-DEV-eap-proj02_ai-amls\n- westeurope\n- MSFT-WEU-EAP_CMN_AI-DEV-RG\nActive vNet: msft-weu-dev-cmnai-vnet\nActive SubNet: \nActive Lake (storage account)  msftweudevcmnai2\nAML for docker: True\n"
     ]
    }
   ],
   "source": [
    "p.describe()"
   ]
  },
  {
   "source": [
    "datastore = p.init() # 3) Automapping from datalake to Azure ML datasets"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...\n",
      "Using GEN2 as Datastore\n",
      "Searching for setting in ESML datalake...\n",
      "ESML in-folder settings override = TRUE \n",
      " - Found settings in the ESML AutoLake  [active_in_folder.json,active_scoring_in_folder.json], to override ArgParse/GIT config with.\n",
      " - TRAIN in date:  2021/01/01\n",
      " - INFERENCE in date: 2021/06/08 and ModelVersion to score with: 1 (0=latest)\n",
      "\n",
      "Load data as Datasets....\n",
      "ds01_diabetes\n",
      "\n",
      "####### Automap & Autoregister - SUCCESS!\n",
      "1) Auto mapped 1 ESML Dataset with registered Azure ML Datasets (potentially all 3: IN,BRONZE, SILVER) in Datastore project002 \n",
      "\n",
      "Dataset 'ds01_diabetes' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "\n",
      "2) Registered each Dataset with suffixes (_IN, _BRONZE, _SILVER) \n",
      " Tip: Use ESMLProject.Datasets list or .DatasetByName(myDatasetName) to read/write\n",
      "#######\n"
     ]
    }
   ]
  },
  {
   "source": [
    "train, evauluate, test = p.split_gold_3(0.6,label)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 2) Azure ML `Edit AutoML generated scoring_script`\n",
    " - Path: `project_specific\\\\model\\\\dev_test_prod\\\\train\\\\automl\\\\scoring_file_dev.py`\n",
    " - DEMO custom script Path: `project_specific\\\\model\\\\dev_test_prod\\\\train\\\\automl\\\\scoring_file_custom.py`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#2a - Download from Azure\n",
    "inference_config_to_override_and_inject, model, best_run = p.get_active_model_inference_config() # 1) You can override this scoring_script - get a baseline, then modify..."
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading AutoML config settings from: dev\n",
      "Loading AutoML config settings from: dev\n",
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.29.0, current version:1.26.0\n",
      "Package:azureml-automl-runtime, training version:1.29.0, current version:1.26.0\n",
      "Package:azureml-core, training version:1.29.0, current version:1.26.0\n",
      "Package:azureml-dataprep, training version:2.15.1, current version:2.13.2\n",
      "Package:azureml-dataprep-native, training version:33.0.0, current version:32.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.13.0, current version:1.11.2\n",
      "Package:azureml-dataset-runtime, training version:1.29.0, current version:1.26.0\n",
      "Package:azureml-defaults, training version:1.29.0, current version:1.26.0\n",
      "Package:azureml-interpret, training version:1.29.0, current version:1.26.0\n",
      "Package:azureml-pipeline-core, training version:1.29.0, current version:1.26.0\n",
      "Package:azureml-telemetry, training version:1.29.0, current version:1.26.0\n",
      "Package:azureml-train-automl-client, training version:1.29.0, current version:1.26.0\n",
      "Package:azureml-train-automl-runtime, training version:1.29.0, current version:1.26.0\n",
      "WARNING:root:Below packages were used for model training but missing in current environment:\n",
      "WARNING:root:Package:azureml-mlflow, training version:1.29.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jostrm\\\\OneDrive - Microsoft\\\\0_GIT\\\\2_My\\\\github\\\\azure-enterprise-scale-ml\\\\settings\\\\project_specific\\\\model\\\\dev_test_prod\\\\train\\\\automl\\\\scoring_file_dev.py'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "inference_config_to_override_and_inject.entry_script # Shows the scoring_script PATH, downloaded locally, ready to be edited and overridden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jostrm\\\\OneDrive - Microsoft\\\\0_GIT\\\\2_My\\\\github\\\\azure-enterprise-scale-ml\\\\settings\\\\project_specific\\\\model\\\\dev_test_prod\\\\train\\\\automl\\\\scoring_file_custom.py'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "#2b - Copy file, and edit, your CUSTOM scoring_script - see example \"scoring_file_custom.py\" ...and overwrite .entry_script\n",
    "\n",
    "my_custom_script_instead = 'scoring_file_custom.py'\n",
    "inference_config_to_override_and_inject.entry_script = 'c:\\\\Users\\\\jostrm\\\\OneDrive - Microsoft\\\\0_GIT\\\\2_My\\\\github\\\\azure-enterprise-scale-ml\\\\settings\\\\project_specific\\\\model\\\\dev_test_prod\\\\train\\\\automl\\\\' + my_custom_script_instead\n",
    "\n",
    "inference_config_to_override_and_inject.entry_script # Verify path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) ESML `Deploy model ONLINE` in `1 line of code` (AKS) \n",
    "- Deploy \"offline\" MODEL from old `run` in environment To →  `DEV`, `TEST` or `PROD` environment\n",
    "- ESML saves `API_key in Azure keyvault automatically`\n",
    "- ESML auto-config solves 4 common 'errors/things': `correct compute name` and `valid replicas, valid agents, valid auto scaling`\n",
    "    - Tip: You can adjust the number of replicas, and different CPU/memory configuration, or using a different compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deploying model: AutoML7d5ab21270 with verison: 1 to environment: dev with overwrite_endpoint=True\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "image_build_compute = prj02-m03-dev\n",
      "Found existing AksWebservice endpoint, deleting it, since overwrite=True\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster, esml-dev-prj02, using it.\n",
      "Note: Autoscale_enabled=False, or since aks_dev_test=True in config, autoscaling is automatically shut off, e.g. overridden in config (since not supported) for environment dev\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-06-14 22:58:47+02:00 Creating Container Registry if not exists.\n",
      "2021-06-14 22:58:47+02:00 Registering the environment.\n",
      "2021-06-14 22:58:48+02:00 Use the existing image.\n",
      "2021-06-14 22:58:50+02:00 Creating resources in AKS.\n",
      "2021-06-14 22:58:50+02:00 Submitting deployment to compute.\n",
      "2021-06-14 22:58:51+02:00 Checking the status of deployment esml-dev-p02-m03-aksapi..\n",
      "2021-06-14 22:59:04+02:00 Checking the status of inference endpoint esml-dev-p02-m03-aksapi.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "2021-06-14T20:58:56,472703718+00:00 - iot-server/run \n",
      "2021-06-14T20:58:56,473476615+00:00 - gunicorn/run \n",
      "2021-06-14T20:58:56,480194692+00:00 - rsyslog/run \n",
      "2021-06-14T20:58:56,495150441+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_d314330ce7ca9373283d99e9999cbce1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_d314330ce7ca9373283d99e9999cbce1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_d314330ce7ca9373283d99e9999cbce1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_d314330ce7ca9373283d99e9999cbce1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_d314330ce7ca9373283d99e9999cbce1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "rsyslogd: /azureml-envs/azureml_d314330ce7ca9373283d99e9999cbce1/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-06-14T20:58:56,601580375+00:00 - iot-server/finish 1 0\n",
      "2021-06-14T20:58:56,603004871+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (10)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 39\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Generating new fontManager, this may take some time...\n",
      "Initializing logger\n",
      "2021-06-14 20:58:58,396 | root | INFO | Starting up app insights client\n",
      "2021-06-14 20:58:58,397 | root | INFO | Starting up request id generator\n",
      "2021-06-14 20:58:58,397 | root | INFO | Starting up app insight hooks\n",
      "2021-06-14 20:58:58,397 | root | INFO | Invoking user's init function\n",
      "2021-06-14 20:59:00,309 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
      "2021-06-14 20:59:00,550 | root | INFO | Users's init has completed successfully\n",
      "2021-06-14 20:59:00,552 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-06-14 20:59:00,552 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-06-14 20:59:00,553 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2021-06-14 20:59:04,374 | root | INFO | 200\n",
      "127.0.0.1 - - [14/Jun/2021:20:59:04 +0000] \"GET /swagger.json HTTP/1.0\" 200 2711 \"-\" \"hackney/1.17.4\"\n",
      "2021-06-14 20:59:09,561 | root | INFO | 200\n",
      "127.0.0.1 - - [14/Jun/2021:20:59:09 +0000] \"GET /swagger.json HTTP/1.0\" 200 2711 \"-\" \"hackney/1.17.4\"\n",
      "\n",
      "Deployed AKS Webservice: esml-dev-p02-m03-aksapi \n",
      "Webservice Uri: https://esmlcmn7skp17.westeurope.cloudapp.azure.com:443/api/v1/service/esml-dev-p02-m03-aksapi/score \n",
      "Webservice API_key are stored in keyvault with name: esml-dev-p02-m03-api \n",
      "Webservice API_URI are stored in keyvault with name: esml-dev-p02-m03-api \n",
      "Webservice Swagger Uri: https://esmlcmn7skp17.westeurope.cloudapp.azure.com:443/api/v1/service/esml-dev-p02-m03-aksapi/swagger.json\n"
     ]
    }
   ],
   "source": [
    "# DEPLOY with custom InferenceConfig (custom scoring script)\n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config_to_override_and_inject, True) #2) (model,inference_config, overwrite_endpoint=True,deployment_config=None):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) ESML Test AKS webservice, `2 lines of code`"
   ]
  },
  {
   "source": [
    "\n",
    "esml_dataset_bronze_df = p.DatasetByName(\"ds01_titanic\").Bronze.to_pandas_dataframe() \n",
    "gold_train = p.save_gold(esml_dataset_bronze_df)  \n",
    "label = \"Survived\"\n",
    "train_set, validate_set, test_set = p.split_gold_3(0.6,label)\n",
    "X_test, y_test, tags = p.get_gold_validate_Xy() \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Pclass                                               Name     Sex   Age  \\\n0       3                           Miss. Bridget O'Driscoll  female  27.0   \n1       2  Mrs. William John Robert (Dorothy Ann Wonnacot...  female  27.0   \n2       2                               Master. Andre Mallet    male   1.0   \n3       1                 Col. Oberst Alfons Simonius-Blumer    male  56.0   \n4       1                        Miss. Jean Gertrude Hippach  female  16.0   \n\n   Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n0                        0                        0   7.7500  \n1                        1                        0  21.0000  \n2                        0                        2  37.0042  \n3                        0                        0  35.5000  \n4                        0                        1  57.9792  \n"
     ]
    }
   ],
   "source": [
    "label = \"Survived\"\n",
    "to_score = None\n",
    "try:\n",
    "    X_test = p.GoldTest.to_pandas_dataframe()\n",
    "    to_score = X_test.drop([label], axis=1)\n",
    "    print(to_score.head()) # gold_test_1 = Dataset.get_by_name(ws, name=p.dataset_gold_test_name_azure)\n",
    "except: \n",
    "    print (\"you need to have splitted GOLD dataset, GoldTest need to exist. Change next cell from MARKDOWN, to CODE, and run that. Try this again... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Relying on you having the keys...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Survived  Pclass                                               Name  \\\n",
       "0           1       3                           Miss. Bridget O'Driscoll   \n",
       "1           0       2  Mrs. William John Robert (Dorothy Ann Wonnacot...   \n",
       "2           1       2                               Master. Andre Mallet   \n",
       "3           1       1                 Col. Oberst Alfons Simonius-Blumer   \n",
       "4           1       1                        Miss. Jean Gertrude Hippach   \n",
       "..        ...     ...                                                ...   \n",
       "528         1       2                           Master. Viljo Hamalainen   \n",
       "529         1       1                                    Mr. Henry Blank   \n",
       "530         0       3                                Mr. Sleiman Attalah   \n",
       "531         0       3                                  Miss. Ida Lefebre   \n",
       "532         0       2                              Mr. John William Gill   \n",
       "\n",
       "        Sex    Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \\\n",
       "0    female  27.00                        0                        0   7.7500   \n",
       "1    female  27.00                        1                        0  21.0000   \n",
       "2      male   1.00                        0                        2  37.0042   \n",
       "3      male  56.00                        0                        0  35.5000   \n",
       "4    female  16.00                        0                        1  57.9792   \n",
       "..      ...    ...                      ...                      ...      ...   \n",
       "528    male   0.67                        1                        1  14.5000   \n",
       "529    male  40.00                        0                        0  31.0000   \n",
       "530    male  30.00                        0                        0   7.2250   \n",
       "531  female   3.00                        3                        1  25.4667   \n",
       "532    male  24.00                        0                        0  13.0000   \n",
       "\n",
       "     result  probability  \n",
       "0         1     0.922252  \n",
       "1         0     0.234340  \n",
       "2         1     0.984918  \n",
       "3         0     0.338251  \n",
       "4         1     0.999310  \n",
       "..      ...          ...  \n",
       "528       1     0.996252  \n",
       "529       0     0.377782  \n",
       "530       0     0.013294  \n",
       "531       0     0.032332  \n",
       "532       0     0.115019  \n",
       "\n",
       "[533 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Siblings/Spouses Aboard</th>\n      <th>Parents/Children Aboard</th>\n      <th>Fare</th>\n      <th>result</th>\n      <th>probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Miss. Bridget O'Driscoll</td>\n      <td>female</td>\n      <td>27.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>1</td>\n      <td>0.922252</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>Mrs. William John Robert (Dorothy Ann Wonnacot...</td>\n      <td>female</td>\n      <td>27.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>21.0000</td>\n      <td>0</td>\n      <td>0.234340</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2</td>\n      <td>Master. Andre Mallet</td>\n      <td>male</td>\n      <td>1.00</td>\n      <td>0</td>\n      <td>2</td>\n      <td>37.0042</td>\n      <td>1</td>\n      <td>0.984918</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Col. Oberst Alfons Simonius-Blumer</td>\n      <td>male</td>\n      <td>56.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>35.5000</td>\n      <td>0</td>\n      <td>0.338251</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Miss. Jean Gertrude Hippach</td>\n      <td>female</td>\n      <td>16.00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>57.9792</td>\n      <td>1</td>\n      <td>0.999310</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>528</th>\n      <td>1</td>\n      <td>2</td>\n      <td>Master. Viljo Hamalainen</td>\n      <td>male</td>\n      <td>0.67</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14.5000</td>\n      <td>1</td>\n      <td>0.996252</td>\n    </tr>\n    <tr>\n      <th>529</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Mr. Henry Blank</td>\n      <td>male</td>\n      <td>40.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31.0000</td>\n      <td>0</td>\n      <td>0.377782</td>\n    </tr>\n    <tr>\n      <th>530</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Mr. Sleiman Attalah</td>\n      <td>male</td>\n      <td>30.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.2250</td>\n      <td>0</td>\n      <td>0.013294</td>\n    </tr>\n    <tr>\n      <th>531</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Miss. Ida Lefebre</td>\n      <td>female</td>\n      <td>3.00</td>\n      <td>3</td>\n      <td>1</td>\n      <td>25.4667</td>\n      <td>0</td>\n      <td>0.032332</td>\n    </tr>\n    <tr>\n      <th>532</th>\n      <td>0</td>\n      <td>2</td>\n      <td>Mr. John William Gill</td>\n      <td>male</td>\n      <td>24.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>0</td>\n      <td>0.115019</td>\n    </tr>\n  </tbody>\n</table>\n<p>533 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "from baselayer_azure_ml import ComputeFactory\n",
    "import json\n",
    "keyvault = p.ws.get_default_keyvault()\n",
    "api_uri = keyvault.get_secret(name='esml-dev-p02-m01-api') # titanic = m01\n",
    "api_key = keyvault.get_secret(name='esml-dev-p02-m01-apisecret') #\n",
    "\n",
    "result_json = ComputeFactory.call_webservice_static(to_score, api_uri,api_key,firstRowOnly=False) # Simulate \"REST call\" (no ESML dependancy)\n",
    "res_dict = json.loads(result_json.text) # json -> dictionary\n",
    "df_res = pd.read_json(res_dict) # dictionary -> pandas\n",
    "all_result = X_test.join(df_res) # features + result\n",
    "all_result"
   ]
  },
  {
   "source": [
    "### Alt 2 - use compute factory, control to `get JSON back` instead of PANDAS. \n",
    "#### `No saving to LAKE`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Note: Fetching keys automatically via workspace keyvault.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Pclass                                               Name     Sex    Age  \\\n",
       "0         3                           Miss. Bridget O'Driscoll  female  27.00   \n",
       "1         2  Mrs. William John Robert (Dorothy Ann Wonnacot...  female  27.00   \n",
       "2         2                               Master. Andre Mallet    male   1.00   \n",
       "3         1                 Col. Oberst Alfons Simonius-Blumer    male  56.00   \n",
       "4         1                        Miss. Jean Gertrude Hippach  female  16.00   \n",
       "..      ...                                                ...     ...    ...   \n",
       "528       2                           Master. Viljo Hamalainen    male   0.67   \n",
       "529       1                                    Mr. Henry Blank    male  40.00   \n",
       "530       3                                Mr. Sleiman Attalah    male  30.00   \n",
       "531       3                                  Miss. Ida Lefebre  female   3.00   \n",
       "532       2                              Mr. John William Gill    male  24.00   \n",
       "\n",
       "     Siblings/Spouses Aboard  Parents/Children Aboard     Fare  result  \\\n",
       "0                          0                        0   7.7500       1   \n",
       "1                          1                        0  21.0000       0   \n",
       "2                          0                        2  37.0042       1   \n",
       "3                          0                        0  35.5000       0   \n",
       "4                          0                        1  57.9792       1   \n",
       "..                       ...                      ...      ...     ...   \n",
       "528                        1                        1  14.5000       1   \n",
       "529                        0                        0  31.0000       0   \n",
       "530                        0                        0   7.2250       0   \n",
       "531                        3                        1  25.4667       0   \n",
       "532                        0                        0  13.0000       0   \n",
       "\n",
       "     probability  \n",
       "0       0.922252  \n",
       "1       0.234340  \n",
       "2       0.984918  \n",
       "3       0.338251  \n",
       "4       0.999310  \n",
       "..           ...  \n",
       "528     0.996252  \n",
       "529     0.377782  \n",
       "530     0.013294  \n",
       "531     0.032332  \n",
       "532     0.115019  \n",
       "\n",
       "[533 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Siblings/Spouses Aboard</th>\n      <th>Parents/Children Aboard</th>\n      <th>Fare</th>\n      <th>result</th>\n      <th>probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Miss. Bridget O'Driscoll</td>\n      <td>female</td>\n      <td>27.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>1</td>\n      <td>0.922252</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Mrs. William John Robert (Dorothy Ann Wonnacot...</td>\n      <td>female</td>\n      <td>27.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>21.0000</td>\n      <td>0</td>\n      <td>0.234340</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Master. Andre Mallet</td>\n      <td>male</td>\n      <td>1.00</td>\n      <td>0</td>\n      <td>2</td>\n      <td>37.0042</td>\n      <td>1</td>\n      <td>0.984918</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Col. Oberst Alfons Simonius-Blumer</td>\n      <td>male</td>\n      <td>56.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>35.5000</td>\n      <td>0</td>\n      <td>0.338251</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Miss. Jean Gertrude Hippach</td>\n      <td>female</td>\n      <td>16.00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>57.9792</td>\n      <td>1</td>\n      <td>0.999310</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>528</th>\n      <td>2</td>\n      <td>Master. Viljo Hamalainen</td>\n      <td>male</td>\n      <td>0.67</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14.5000</td>\n      <td>1</td>\n      <td>0.996252</td>\n    </tr>\n    <tr>\n      <th>529</th>\n      <td>1</td>\n      <td>Mr. Henry Blank</td>\n      <td>male</td>\n      <td>40.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>31.0000</td>\n      <td>0</td>\n      <td>0.377782</td>\n    </tr>\n    <tr>\n      <th>530</th>\n      <td>3</td>\n      <td>Mr. Sleiman Attalah</td>\n      <td>male</td>\n      <td>30.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.2250</td>\n      <td>0</td>\n      <td>0.013294</td>\n    </tr>\n    <tr>\n      <th>531</th>\n      <td>3</td>\n      <td>Miss. Ida Lefebre</td>\n      <td>female</td>\n      <td>3.00</td>\n      <td>3</td>\n      <td>1</td>\n      <td>25.4667</td>\n      <td>0</td>\n      <td>0.032332</td>\n    </tr>\n    <tr>\n      <th>532</th>\n      <td>2</td>\n      <td>Mr. John William Gill</td>\n      <td>male</td>\n      <td>24.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>0</td>\n      <td>0.115019</td>\n    </tr>\n  </tbody>\n</table>\n<p>533 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "result, model_version_used = p.compute_factory.call_webservice(to_score,False,False) # (X_test, firstRowOnly=True,pandas_result=True, api_uri=None,api_key=\"auto from keyvault\")\n",
    "df_res = pd.read_json(result)\n",
    "all_result = to_score.join(df_res) # Need to join the FEATURES yourself, post webservice call (simulate no ESML dependancy in caller)\n",
    "all_result"
   ]
  },
  {
   "source": [
    "### Alt 3 - ESML.call_webservice, `get PANDAS joined` dataframe\n",
    "#### `Also saves to LAKE, automatically` \n",
    "- Requires p.init() or to manually set lake `p.lakestore = p.set_lake_as_datastore(p.ws)`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using GEN2 as Datastore\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Note: Fetching keys automatically via workspace keyvault.\n",
      "Saving scoring to lake for project folder project002 and inference_model_version: 2 ...\n",
      "...\n",
      "\n",
      "Saved DATA to score successfully in LAKE, as file 'to_score_caller_id.parquet'\n",
      "Saved SCORED data in LAKE, as file 'scored_caller_id.parquet'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                           Miss. Bridget O'Driscoll  female  27.0   \n",
       "1       2  Mrs. William John Robert (Dorothy Ann Wonnacot...  female  27.0   \n",
       "2       2                               Master. Andre Mallet    male   1.0   \n",
       "3       1                 Col. Oberst Alfons Simonius-Blumer    male  56.0   \n",
       "4       1                        Miss. Jean Gertrude Hippach  female  16.0   \n",
       "\n",
       "   Siblings/Spouses Aboard  Parents/Children Aboard     Fare  result  \\\n",
       "0                        0                        0   7.7500       1   \n",
       "1                        1                        0  21.0000       0   \n",
       "2                        0                        2  37.0042       1   \n",
       "3                        0                        0  35.5000       0   \n",
       "4                        0                        1  57.9792       1   \n",
       "\n",
       "   probability  \n",
       "0     0.922252  \n",
       "1     0.234340  \n",
       "2     0.984918  \n",
       "3     0.338251  \n",
       "4     0.999310  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Siblings/Spouses Aboard</th>\n      <th>Parents/Children Aboard</th>\n      <th>Fare</th>\n      <th>result</th>\n      <th>probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Miss. Bridget O'Driscoll</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>1</td>\n      <td>0.922252</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Mrs. William John Robert (Dorothy Ann Wonnacot...</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>21.0000</td>\n      <td>0</td>\n      <td>0.234340</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Master. Andre Mallet</td>\n      <td>male</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>37.0042</td>\n      <td>1</td>\n      <td>0.984918</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Col. Oberst Alfons Simonius-Blumer</td>\n      <td>male</td>\n      <td>56.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>35.5000</td>\n      <td>0</td>\n      <td>0.338251</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Miss. Jean Gertrude Hippach</td>\n      <td>female</td>\n      <td>16.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>57.9792</td>\n      <td>1</td>\n      <td>0.999310</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "p.lakestore = p.set_lake_as_datastore(p.ws) # only needed if NOT p.init() is done\n",
    "df = p.call_webservice(p.ws, to_score,\"caller_id\") # (X_test, firstRowOnly=True,pandas_result=True, api_uri=None,api_key=\"auto from keyvault\")\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Optional: You can ALSO customize DeployConfig for AKS, programmatically...\n",
    "- Can be done, `BUT recommendation is to use the \"settings/\" folder instead`, to override performance settings in .json per each evnironment (dev,test,prod)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\nNote: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\nNote: Autoscale_enabled=False, or since aks_dev_test=True in config, autoscaling is automatically shut off, e.g. overridden in config (since not supported) for environment dev\ndescription: AKS webserice in DEV environment.\ntags:  {'environment': 'dev'}\nCPU requirement: 1, Memory requirement: 8GB, Number of replica: 1\nconfig:  None\nconfig - cpu_cores_limit (override what you want):  None\n"
     ]
    }
   ],
   "source": [
    "deploy_config_to_override_and_inject = p.get_deploy_config_aks()  # 2) Optional: you can also override this - get a baseline, then modify...\n",
    "\n",
    "print(\"description:\", deploy_config_to_override_and_inject.description)\n",
    "print(\"tags: \", deploy_config_to_override_and_inject.tags)\n",
    "print(\"config: \", deploy_config_to_override_and_inject.print_deploy_configuration())\n",
    "print(\"config - cpu_cores_limit (override what you want): \", deploy_config_to_override_and_inject.cpu_cores_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPLOY with custom DeployConfig\n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config_to_override_and_inject, True, own_deploy_config_to_inject) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading AutoML config settings from: dev\n",
      "Loading AutoML config settings from: dev\n",
      "Deploying model: AutoML449305f300 with verison: 1 to environment: dev with overwrite_endpoint=True\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing AksWebservice endpoint, deleting it, since overwrite=True\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster, esml-dev-prj02, using it.\n",
      "Note: Autoscale_enabled=False, or since aks_dev_test=True in config, autoscaling is automatically shut off, e.g. overridden in config (since not supported) for environment dev\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-04-17 04:01:28+02:00 Creating Container Registry if not exists.\n",
      "2021-04-17 04:01:28+02:00 Registering the environment.\n",
      "2021-04-17 04:01:28+02:00 Use the existing image.\n",
      "2021-04-17 04:01:30+02:00 Creating resources in AKS.\n",
      "2021-04-17 04:01:31+02:00 Submitting deployment to compute.\n",
      "2021-04-17 04:01:31+02:00 Checking the status of deployment esml-dev-p02-m03-aksapi..\n",
      "2021-04-17 04:01:53+02:00 Checking the status of inference endpoint esml-dev-p02-m03-aksapi.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "2021-04-17T02:01:46,835849360+00:00 - rsyslog/run \n",
      "2021-04-17T02:01:46,836611450+00:00 - gunicorn/run \n",
      "2021-04-17T02:01:46,844303750+00:00 - iot-server/run \n",
      "2021-04-17T02:01:46,848060001+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_8e5a5a51349877e7d47c6a2872e0ebfd/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_8e5a5a51349877e7d47c6a2872e0ebfd/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_8e5a5a51349877e7d47c6a2872e0ebfd/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_8e5a5a51349877e7d47c6a2872e0ebfd/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_8e5a5a51349877e7d47c6a2872e0ebfd/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "rsyslogd: /azureml-envs/azureml_8e5a5a51349877e7d47c6a2872e0ebfd/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-04-17T02:01:46,944838041+00:00 - iot-server/finish 1 0\n",
      "2021-04-17T02:01:46,946316522+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 40\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Generating new fontManager, this may take some time...\n",
      "Initializing logger\n",
      "2021-04-17 02:01:48,236 | root | INFO | Starting up app insights client\n",
      "2021-04-17 02:01:48,236 | root | INFO | Starting up request id generator\n",
      "2021-04-17 02:01:48,236 | root | INFO | Starting up app insight hooks\n",
      "2021-04-17 02:01:48,236 | root | INFO | Invoking user's init function\n",
      "2021-04-17 02:01:50,584 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
      "2021-04-17 02:01:50,812 | root | INFO | Users's init has completed successfully\n",
      "2021-04-17 02:01:50,814 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-04-17 02:01:50,814 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-04-17 02:01:50,815 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2021-04-17 02:01:53,880 | root | INFO | 200\n",
      "127.0.0.1 - - [17/Apr/2021:02:01:53 +0000] \"GET /swagger.json HTTP/1.0\" 200 2634 \"-\" \"-\"\n",
      "2021-04-17 02:02:01,636 | root | INFO | 200\n",
      "127.0.0.1 - - [17/Apr/2021:02:02:01 +0000] \"GET /swagger.json HTTP/1.0\" 200 2634 \"-\" \"-\"\n",
      "\n",
      "Deployed AKS Webservice: esml-dev-p02-m03-aksapi \n",
      "Webservice Uri: https://esmlcmn7skp17.westeurope.cloudapp.azure.com:443/api/v1/service/esml-dev-p02-m03-aksapi/score \n",
      "Webservice API_key are stored in keyvault with name: esml-dev-p02-m03-api \n",
      "Webservice API_URI are stored in keyvault with name: esml-dev-p02-m03-api \n",
      "Webservice Swagger Uri: https://esmlcmn7skp17.westeurope.cloudapp.azure.com:443/api/v1/service/esml-dev-p02-m03-aksapi/swagger.json\n"
     ]
    }
   ],
   "source": [
    "inference_config, model, best_run = p.get_active_model_inference_config(ws) #  AutoML support \n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config,True) #2) (model,inference_config, overwrite_endpoint=True,deployment_config=None):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "interpreter": {
   "hash": "3fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}