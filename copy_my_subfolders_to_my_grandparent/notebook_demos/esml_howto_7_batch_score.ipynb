{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESML - accelerator: Batch scoring pipeline\n",
    "- 1) `AutoMap datalake` & init ESML project\n",
    "- 2) `Get earlier trained model`\n",
    "- 3) `Score with GOLD_TEST` and calculate ML-performance\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "######  NB! This,InteractiveLoginAuthentication, is only needed to run 1st time, then when ws_config is written, use later CELL in notebook, that just reads that file\n",
    "import repackage\n",
    "repackage.add(\"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "\n",
    "p = ESMLProject()\n",
    "p.dev_test_prod=\"dev\"\n",
    "auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "ws, config_name = p.authenticate_workspace_and_write_config(auth)\n",
    "######  NB!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregister_all_datasets=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import repackage\n",
    "repackage.add(\"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "\n",
    "p = ESMLProject() # Will search in ROOT for your copied SETTINGS folder '../../../settings', you should copy template settings from '../settings'\n",
    "p.ws = p.get_workspace_from_config() #2) Load DEV or TEST or PROD Azure ML Studio workspace\n",
    "p.inference_mode = True\n",
    "\n",
    "if(unregister_all_datasets):\n",
    "    p.unregister_all_datasets(p.ws) # For DEMO purpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inference mode (otherwise Training mode): True\nInference version: 4\n\n - ds01_titanic\nprojects/project002/01_titanic_model_clas/inference/4/ds01_titanic/in/dev/2021/06/16/\nprojects/project002/01_titanic_model_clas/inference/4/ds01_titanic/out/bronze/dev/\nprojects/project002/01_titanic_model_clas/inference/4/ds01_titanic/out/silver/dev/\nprojects/project002/01_titanic_model_clas/inference/4/ds01_titanic/in/dev/2021/06/16/\n \n\nTraining GOLD (p.GoldPath)\nprojects/project002/01_titanic_model_clas/inference/4/gold/dev/\n \n\n[A) USAGE]: to_score_folder, scored_folder, date_folder = p.get_gold_scored_unique_path()\nA)INFERENCE ONLINE: GOLD to score (example if realtime - today)\nprojects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_17/5da0f00f3c6d4a34989de39f7b44ffdb/\n \n\nA)INFERENCE ONLINE: GOLD scored (example if realtime today)\nprojects/project002/01_titanic_model_clas/inference/4/scored/dev/2021_06_17/5da0f00f3c6d4a34989de39f7b44ffdb/\n \n\n[B) USAGE]: to_score_folder_batch, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder)\nB)INFERENCE BATCH: GOLD to score (example batch, datetime from config)\nprojects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/befa75135d5e438482af0be189178f7a/\n \n\nB)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\nprojects/project002/01_titanic_model_clas/inference/4/scored/dev/2021_06_16/befa75135d5e438482af0be189178f7a/\n \n\nC) INFERENCE BATCH (SCENARIO 2): TODAY I scored data from X days AGO  (second datefolder from config - X days ago)\nprojects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/befa75135d5e438482af0be189178f7a/2021_06_16/\nprojects/project002/01_titanic_model_clas/inference/4/scored/dev/2021_06_16/befa75135d5e438482af0be189178f7a/2021_06_16/\n \n\nENVIRONMENT - DEV, TEST, or PROD?  [USAGE: p.dev_test_prod]\nACTIVE ENVIRONMENT = dev\nACTIVE subscription = ca0a8c40-b06a-4e4e-8434-63c03a1dee34\n- MSFT-WEU-EAP_PROJECT02_AI-DEV-RG\n- msft-weu-DEV-eap-proj02_ai-amls\n- westeurope\n- MSFT-WEU-EAP_CMN_AI-DEV-RG\nActive vNet: msft-weu-dev-cmnai-vnet\nActive SubNet: \n[USAGE] for the above: p.vNetForActiveEnvironment()\nActive Lake (storage account)  msftweudevcmnai2\n[USAGE] for the above: p.getLakeForActiveEnvironment()\nAML for docker: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Inference mode (otherwise Training mode):\", p.inference_mode)\n",
    "p.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...\n",
      "Using GEN2 as Datastore\n",
      "Searching for setting in ESML datalake...\n",
      "ESML in-folder settings override = FALSE. [active_in_folder.json,active_scoring_in_folder.json] not found. \n",
      " - Using [active_in_folder.json,active_scoring_in_folder.json] from ArgParse or GIT. No override from datalake settings\n",
      "\n",
      "Inference mode (False = Training mode): True\n",
      "Load data as Datasets....\n",
      "ds01_titanic\n",
      "\n",
      "####### Automap & Autoregister - SUCCESS!\n",
      "1) Auto mapped 1 ESML Dataset with registered Azure ML Datasets (potentially all 3: IN,BRONZE, SILVER) in Datastore project002 \n",
      "\n",
      "Dataset 'ds01_titanic' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "\n",
      "2) Registered each Dataset with suffixes (_IN, _BRONZE, _SILVER) \n",
      " Tip: Use ESMLProject.Datasets list or .DatasetByName(myDatasetName) to read/write\n",
      "#######\n"
     ]
    }
   ],
   "source": [
    "datastore = p.init() # 3) Automapping from datalake to Azure ML datasets"
   ]
  },
  {
   "source": [
    "#  SCORING PIPELINE - `ESML AutoLake paths` for SCORING"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1) REAL-TIME & ONLINE AKS webservice\n",
    "- No data exists in IN-folder as for BATCH scoring, data comes as GOLD from REST call, but is saved automatically by ESML in \"GOLD to_score\" (for lineage purpose)\n",
    "    - Assuming, Bronze2Gold is taken care of by another pipeline (ADF or AML)\n",
    "- WriteBack function: Use the 2nd print out, If you want to create a \"daily report\" or writeback data to a \"source\" with the prediction. Read this scored data from ESML AutoLake"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A)TO SCORE -  INFERENCE ONLINE: GOLD to score (example if realtime - today)\nprojects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_17/a896d979d55b42edbd9f9c2cd8f2d54d/\n\n ...above reading, is not required for ONLINE (data via REST), but good for lineage - to save REST-data, see what data was scored by the AKS-endpoint\n\nA)SCORED - INFERENCE ONLINE: GOLD scored (example if realtime today)\n\nprojects/project002/01_titanic_model_clas/inference/4/scored/dev/2021_06_17/a896d979d55b42edbd9f9c2cd8f2d54d/\n\n"
     ]
    }
   ],
   "source": [
    "to_score_folder, scored_folder, date_folder = p.get_gold_scored_unique_path()\n",
    "print(\"A)TO SCORE -  INFERENCE ONLINE: GOLD to score (example if realtime - today)\")\n",
    "print(to_score_folder)\n",
    "print(\"\")\n",
    "print(\" ...above reading, is not required for ONLINE (data via REST), but good for lineage - to save REST-data, see what data was scored by the AKS-endpoint\")\n",
    "print(\"\")\n",
    "print(\"A)SCORED - INFERENCE ONLINE: GOLD scored (example if realtime today)\")\n",
    "print(\"\")\n",
    "print(scored_folder)\n",
    "print(\"\")"
   ]
  },
  {
   "source": [
    "# 2) BATCH SCORING `IN -> Bronze->Silver`\n",
    "- BATCH? REALTIME / ONLINE scoring with AKS, can also score multiple rows, but if there's a lot of data to score or ONLINE webservice is not needed, use this approach instead.\n",
    "- Bronze2Gold: Refinement is needed from IN->Bronze-Silver for each dataset, then merge all to 1 GOLD. \n",
    "    - This procedure can be a `pipeline` (ADF or AML) or a `piplinestep`. Example of the latter: The 1st AML `Bronze2Gold`-piplinestep before a 2nd `ScoringStep`\n",
    "    - Last action is to MERGE all silver-states to 1 GOLD dataset, which another pipeline (or pipelinestep) are targeting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2A) ESML auotomatically saves \"to_score\" and \"scored\" - `aligend to Datalake design`\n",
    "- ESML Feture engineering: `Bronze 2 Gold` for inference\n",
    "- `Benefits`: User `do not need to remember any paths` in datalake\n",
    "- -Cons: created an ESML SDK dependancy in the Azure Databricks notebook, or Azure ML Bronze2Gold Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "projects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/\n"
     ]
    }
   ],
   "source": [
    "print(p.GoldPathToScoreBatch) # This is the GOAL. After Bronze2Gold we have this folder"
   ]
  },
  {
   "source": [
    "## `Bronze2Gold` - prep data `to_score`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "projects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/\nprojects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/94b3af25c2014f90bfed2af07d155664/\n"
     ]
    }
   ],
   "source": [
    "# Feture engineering: Bronze 2 Gold - working with Azure ML Datasets with Bronze, Silver, Gold concept\n",
    "esml_dataset = p.DatasetByName(\"ds01_titanic\") # Get dataset\n",
    "df_bronze = esml_dataset.Bronze.to_pandas_dataframe()\n",
    "p.save_silver(esml_dataset,df_bronze) #Bronze -> Silver\n",
    "\n",
    "df = esml_dataset.Silver.to_pandas_dataframe() \n",
    "gold_to_score, to_score_version_folder = p.save_gold(df)  #Silver -> Gold\n",
    "\n",
    "print(p.GoldPathToScoreBatch)\n",
    "print(to_score_version_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "projects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/*/*.parquet\nprojects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/94b3af25c2014f90bfed2af07d155664/\n"
     ]
    }
   ],
   "source": [
    "print(p.GoldPathToScoreBatch + '*/*.parquet')\n",
    "print(to_score_version_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('project002', 'projects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/94b3af25c2014f90bfed2af07d155664/*.parquet')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ReadParquetFile\",\n",
       "    \"DropColumns\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"4723785c-d4ff-4741-a7ac-4612269bd1f7\",\n",
       "    \"name\": \"M01_GOLD_TO_SCORE\",\n",
       "    \"version\": 2,\n",
       "    \"description\": \"01_titanic_model_clas: GOLD_to_score.parquet\",\n",
       "    \"tags\": {\n",
       "      \"date_time_folder\": \"2021_06_16\",\n",
       "      \"model_version\": \"4\",\n",
       "      \"model\": \"01_titanic_model_clas\"\n",
       "    },\n",
       "    \"workspace\": \"Workspace.create(name='msft-weu-DEV-eap-proj02_ai-amls', subscription_id='ca0a8c40-b06a-4e4e-8434-63c03a1dee34', resource_group='MSFT-WEU-EAP_PROJECT02_AI-DEV-RG')\"\n",
       "  }\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "Dataset.get_by_name(workspace = p.ws, name =  \"M01_GOLD_TO_SCORE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TabularDataset\n{\n  \"source\": [\n    \"('project002', 'projects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/94b3af25c2014f90bfed2af07d155664/*.parquet')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\",\n    \"ReadParquetFile\",\n    \"DropColumns\"\n  ],\n  \"registration\": {\n    \"id\": \"4723785c-d4ff-4741-a7ac-4612269bd1f7\",\n    \"name\": \"M01_GOLD_TO_SCORE\",\n    \"version\": 2,\n    \"description\": \"01_titanic_model_clas: GOLD_to_score.parquet\",\n    \"tags\": {\n      \"date_time_folder\": \"2021_06_16\",\n      \"model_version\": \"4\",\n      \"model\": \"01_titanic_model_clas\"\n    },\n    \"workspace\": \"Workspace.create(name='msft-weu-DEV-eap-proj02_ai-amls', subscription_id='ca0a8c40-b06a-4e4e-8434-63c03a1dee34', resource_group='MSFT-WEU-EAP_PROJECT02_AI-DEV-RG')\"\n  }\n}\n"
     ]
    }
   ],
   "source": [
    "print(p.Gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2 ways to find same Dataset: M01_GOLD_TO_SCORE\nQ: OK. Yes, the path exists, including GUID-folder in Azure ML:  True\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "ds = Dataset.get_by_name(workspace = p.ws, name =  p.Gold.name) # Opton 1) Azure ML Dataset directly\n",
    "ds = Dataset.get_by_name(workspace = p.ws, name =  \"M01_GOLD_TO_SCORE\") # Opton 2) This would be static for this model, always same, fetches latest version\n",
    "\n",
    "\n",
    "if(ds.name != p.Gold.name): # Opton 2) ESMLProject.Gold property\n",
    "    print (\"error\")\n",
    "else: \n",
    "    print (\"2 ways to find same Dataset: {}\".format( p.Gold.name))\n",
    "    print(\"Q: OK. Yes, the path exists, including GUID-folder in Azure ML: \", to_score_version_folder in str(p.Gold))"
   ]
  },
  {
   "source": [
    "## 2B) Manually \"to_score\" and \"scored\" - still `alignd to Datalake design` (with help from ESML)\n",
    "- Azure ML Feture engineering: `Bronze 2 Gold` for inference, but with Azure ML Datasets directly (not via ESML)\n",
    "- `Benefits`: No ESML SDK dependancy to DEFINE the pipepline \"Pythoncript\" (to execute it, ESML never is needed).\n",
    "- Cons: \n",
    "    - You cannot user ESML Bronze2Gold concept in your Azure ML Bronze2Gold Pipeline (since not installed), you need to:\n",
    "    - Manually write dynamic data-paths to Datalake GEN 2 (work with `date_folder paths`, `model_version` `dev,test,prod`, `datasets`, `bronze,silver, gold` (which ESML still can help genereate) \n",
    "    - Manually register your Datasets manually in Azure ML Studio, with versioning, and with naming convention on Dataset names, and manually TAG datasets with metadata (date_folder, etc)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ds01_titanic\nIN projects/project002/01_titanic_model_clas/inference/4/ds01_titanic/in/dev/2021/06/16/\nBronze projects/project002/01_titanic_model_clas/inference/4/ds01_titanic/out/bronze/dev/\nSilver projects/project002/01_titanic_model_clas/inference/4/ds01_titanic/out/silver/dev/\n\nGold to SCORE:  projects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/e698211ce52f4d0bbfef67f6ed40b83b/   ...uuid folder, is to be able to have multiple unique scorings, same datetime\n\n...bronze2Gold here, manually upload to datalake  (manually register dataset if needed)\n\nGold to SCORED:  projects/project002/01_titanic_model_clas/inference/4/scored/dev/2021_06_16/e698211ce52f4d0bbfef67f6ed40b83b/\n"
     ]
    }
   ],
   "source": [
    "p.inference_mode = True # This flag will \"change the paths\", from TRAIN folder to INFERENCE folder-structure\n",
    "\n",
    "for d in p.Datasets:\n",
    "    print(d.Name)\n",
    "    print(\"IN\", d.InPath)\n",
    "    print(\"Bronze\", d.BronzePath)\n",
    "    print(\"Silver\", d.SilverPath)\n",
    "\n",
    "# MANUALLY - Get help Generate 2 paths...use them to manually save \"to_score\" and \"scored\"\n",
    "to_score_folder, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder) \n",
    "print()\n",
    "print(\"Gold to SCORE: \", to_score_folder, \"  ...uuid folder, is to be able to have multiple unique scorings, same datetime\")\n",
    "print()\n",
    "print(\"...bronze2Gold here, manually upload to datalake  (manually register dataset if needed)\")\n",
    "print()\n",
    "print(\"Gold to SCORED: \", scored_folder)\n"
   ]
  },
  {
   "source": [
    "# `TRAIN` example (p.`inference_mode = False`)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ds01_titanic\n",
      "IN projects/project002/01_titanic_model_clas/train/ds01_titanic/in/dev/2021/01/16/\n",
      "Bronze projects/project002/01_titanic_model_clas/train/ds01_titanic/out/bronze/dev/\n",
      "Silver projects/project002/01_titanic_model_clas/train/ds01_titanic/out/silver/dev/\n",
      "Gold TRAIN projects/project002/01_titanic_model_clas/train/gold/dev/Train/*/ *.parquet\n",
      "Gold TRAIN TabularDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('project002', 'projects/project002/01_titanic_model_clas/train/gold/dev/Train/5b37804fff294e1b93b2bd9fa763e2fa/*.parquet')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ReadParquetFile\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"d646ef17-1159-4a5a-9b0f-7b20aebe2a9d\",\n",
      "    \"name\": \"M01_GOLD_TRAIN\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"01_titanic_model_clasGOLD_TRAIN.parquet from splitted Train, Validate, Test\",\n",
      "    \"tags\": {\n",
      "      \"split_percentage\": \"0.6\",\n",
      "      \"label\": \"Survived\",\n",
      "      \"model\": \"01_titanic_model_clas\"\n",
      "    },\n",
      "    \"workspace\": \"Workspace.create(name='msft-weu-DEV-eap-proj02_ai-amls', subscription_id='ca0a8c40-b06a-4e4e-8434-63c03a1dee34', resource_group='MSFT-WEU-EAP_PROJECT02_AI-DEV-RG')\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "p.inference_mode = False # Example for flag set to TRAIN mode\n",
    "\n",
    "for d in p.Datasets:\n",
    "    print(d.Name)\n",
    "    print(\"IN\", d.InPath) # datefolder, reads from Datalake Active folder\n",
    "    print(\"Bronze\", d.BronzePath) # intermediate\n",
    "    print(\"Silver\", d.SilverPath) # intermediate\n",
    "\n",
    "print(\"Gold TRAIN\", p.GoldPath + 'Train/*/', \"*.parquet\") # Gold/Env/Train/versionfolder/data.parquet\n",
    "print(\"Gold TRAIN\", p.GoldTrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2 ways to find same Dataset: M01_GOLD\nQ: OK. Yes, the path exists, including GUID-folder in Azure ML:  False\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.dataset import Dataset \n",
    "ds1 = Dataset.get_by_name(workspace = p.ws, name =  p.Gold.name) # Opton 1) Azure ML Dataset directly\n",
    "ds2 = Dataset.get_by_name(workspace = p.ws, name = \"M01_GOLD_TO_SCORE\") # Opton 2) This would be static for this model, fetches latest version\n",
    "\n",
    "if(ds1.name != p.Gold.name and ds2.name != p.Gold.name): # Opton 3) ESMLProject.Gold property\n",
    "    print (\"error\", ds2.name)\n",
    "    print (\"error\", p.Gold.name)\n",
    "else: \n",
    "    print (\"2 ways to find same Dataset: {}\".format( p.Gold.name))\n",
    "    print(\"Q: OK. Yes, the path exists, including GUID-folder in Azure ML: \", to_score_version_folder in str(p.Gold))"
   ]
  },
  {
   "source": [
    "# BATCH SCORING `GOLD` (\"to_score\" and \"scored\" folders)\n",
    "- Assuming another pipeline (ADF or AML) has already refined data from `IN->Bronze->Silver->Gold`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A)INFERENCE BATCH - ALL scorings that day (datetime from config)\nprojects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/*/*.parquet\n\nB)INFERENCE BATCH - LATEST scoring that day\nprojects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/gold_to_score.parquet\n\n\n"
     ]
    }
   ],
   "source": [
    "print(\"A)INFERENCE BATCH - ALL scorings that day (datetime from config)\")\n",
    "print(p.GoldPathToScoreBatch + '*/*.parquet')\n",
    "print(\"\")\n",
    "print(\"B)INFERENCE BATCH - LATEST scoring that day\")\n",
    "print(p.GoldPathToScoreBatch + 'gold_to_score.parquet')\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C)INFERENCE BATCH: SPECIFIC scoring, that day (generate paths to simulate, datetime from config)\nprojects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/5096b4e54d344aa290f8402cb78f7d33/gold_to_score.parquet\n\nD)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\nprojects/project002/01_titanic_model_clas/inference/4/scored/dev/2021_06_16/5096b4e54d344aa290f8402cb78f7d33/scored_*.parquet\n\n...The UUID folder at the end, MAIN PURPOSE, to enable multiple unique scorings same day. But can be overridden with a surrogate key, e.g. customerID\n"
     ]
    }
   ],
   "source": [
    "to_score_folder_batch, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder)\n",
    "\n",
    "print(\"C)INFERENCE BATCH: SPECIFIC scoring, that day (generate paths to simulate, datetime from config)\")\n",
    "print(to_score_folder_batch + 'gold_to_score.parquet') # + self.date_scoring_folder.strftime('%Y_%m_%d') + '/')\n",
    "print(\"\")\n",
    "print(\"D)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\")\n",
    "print(scored_folder +  'scored_*.parquet') \n",
    "print(\"\")\n",
    "print(\"...The UUID folder at the end, MAIN PURPOSE, to enable multiple unique scorings same day. But can be overridden with a surrogate key, e.g. customerID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "my_unique_folder_customerID = uuid.uuid4().hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-> INJECT static guid-folder\n\nE)INFERENCE BATCH: GOLD to score (example batch, datetime from config)\nprojects/project002/01_titanic_model_clas/inference/22/gold/dev/2021_01_21/aa2b9f27b75c47e180f4cb72630996c7/gold_to_score.parquet\n\nE)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\nprojects/project002/01_titanic_model_clas/inference/22/scored/dev/2021_01_21/aa2b9f27b75c47e180f4cb72630996c7/scored_*.parquet\n\n"
     ]
    }
   ],
   "source": [
    "# Using a STATIC uuid, can be a \"sytem_caller_id\" (1-M systems scores data same day), or an ID for a target database for WriteBackFunction, or an external way to see \"Customer_ID\"\n",
    "to_score_folder_batch, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder, my_unique_folder_customerID)\n",
    "\n",
    "print(\"-> INJECT static guid-folder\")\n",
    "print(\"\")\n",
    "print(\"E)INFERENCE BATCH: GOLD to score (example batch, datetime from config)\")\n",
    "print(to_score_folder_batch + 'gold_to_score.parquet') # + self.date_scoring_folder.strftime('%Y_%m_%d') + '/')\n",
    "print(\"\")\n",
    "print(\"E)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\")\n",
    "print(scored_folder +  'scored_*.parquet') \n",
    "print(\"\")"
   ]
  },
  {
   "source": [
    "# Disaster recovery scenario\n",
    "- Disaster: If pipeline has not been running for days, we need to score data back in time, and do WriteBack to that data maybe\n",
    "- ESML allows to have 2 datefolders: \"Today WEDNESDAY I cored data from last MONDAY\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C) INFERENCE BATCH (SCENARIO 2): TODAY I scored data from X days AGO  (second datefolder from config - X days ago)\n \n\nprojects/project002/03_diabetes_model_reg/inference/1/gold/dev/2021_06_08/65c9531aa0bd4a8b8c15dfd2163b1629/2021_06_08/\nprojects/project002/03_diabetes_model_reg/inference/1/scored/dev/2021_06_08/65c9531aa0bd4a8b8c15dfd2163b1629/2021_06_08/\n"
     ]
    }
   ],
   "source": [
    "print(\"C) INFERENCE BATCH (SCENARIO 2): TODAY I scored data from X days AGO  (second datefolder from config - X days ago)\")\n",
    "print(\" \\n\")\n",
    "print(to_score_folder_batch + p.date_scoring_folder.strftime('%Y_%m_%d') + '/')\n",
    "print(scored_folder + p.date_scoring_folder.strftime('%Y_%m_%d') + '/')"
   ]
  },
  {
   "source": [
    "# 1) SCORING PIPELINE (remote CPU cluster)\n",
    "### 3 Parameters (environment, model_version, scoring_folder_date)\n",
    "- Parameters from \"calling orchestrator\" can be either \n",
    "    - A) written to Datalake json, before the pipeline is triggered.\n",
    "    - B) passed to the AML pipline (Azure Datafactory passes 3 parameters to this AML scoring pipeline)\n",
    "- NB! The default behaviour is for ESML to read these 3 parameters from datalake \"active\" folder (json file) \"project002/modelA/inference/active/*.json\" at ESMLProject.init()\n",
    "    - But, these 3 parameters can be passed directly, which will override the ones in the DataLake\n",
    "        - A) passing them to the ESMLProject constructor (Use case: Debugging purpose)\n",
    "        - B) passing them on the Python command line as `STRINGS`, to let ESML read from ArgumentParser (Use case: From Azure Devops Build & Release piplines, or from Azure Datafactory AML activity)\n",
    "            - ESMLProject.get_project_from_env_command_line() will then do the below. \n",
    "                - `parser.add_argument('--esml_environment', type=str, help='ESML target environment: dev,test,prod')`\n",
    "                - `parser.add_argument('--esml_inference_model_version', type=str, help='Model version to score with')`\n",
    "                - `parser.add_argument('--esml_scoring_in_datetime', type=str, help='IN folder, datetype:datetime - the data to SCORE date_folder')`\n",
    "                - `parser.add_argument('--esml_train_in_datetime', type=str, help='IN folder. datetype:datetime - the data to RETRAIN model on')`\n",
    "            - NB! If `esml_inference_model_version` is `not set/None/Null or negative`...ESML will be ready for \"retraining\" rather than \"inference/scoring\"\n",
    "            - NB! If `esml_inference_model_version`=\"`0`\"...ESML will be use the highest&latest model version, to score with."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Override `ACTIVE data & model` from Lake-config, with ArgParse and ESMLProject constructor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Parameters from \"calling orchestrator\" = Azure Data factory as ab AML pipline activity \n",
    "# Note: The default behaviour is for ESML to read these parameters from datalake \"active\" folder (json file) \"project002/modelA/inference/active/*.json\" \n",
    "# But these can be passed directly, to override that, as seen below:\n",
    "\n",
    "param_esml_env = \"dev\"\n",
    "param_inference_model_version = \"4\"\n",
    "param_scoring_folder_date = \"2021-06-16 15:35:01.243860\" # will become both IN and GOLD path:  \n",
    "# inference/1/gold/dev/2021_06_08/1a51b4c19bec4409b61c52fa516e5aa2/\n",
    "# inference/1/scored/dev/2021_06_08/1a51b4c19bec4409b61c52fa516e5aa2/\n",
    "param_train_in_folder_date = \"2021-01-16 15:35:01.243860\" # \n",
    "\n",
    "optional_param_my_unique_scoring_folder = \"22698b40d7d74d8c92b5fd8891d8a009\""
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lakestore = p.set_lake_as_datastore(ws)\n",
    "#p.readActiveDatesFromLake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "json_date_in_folder {'dev_in_folder_date': '2021-01-16 15:35:01.243860', 'test_in_folder_date': '2021-01-21 15:35:01.243860', 'prod_in_folder_date': '2020-01-01 15:35:01.243860'}\n",
      "json_date_scoring_folder {'dev_scoring_folder_date': '2021-06-16 15:35:01.243860', 'test_scoring_folder_date': '2021-01-21 15:35:01.243860', 'prod_scoring_folder_date': '2020-01-01 15:35:01.243860', 'dev_inference_model_version': '4', 'test_inference_model_version': '22', 'prod_inference_model_version': '0'}\n",
      "Inference version: 4\n",
      "\n",
      " - ds01_titanic\n",
      "projects/project002/01_titanic_model_clas/inference/4/ds01_titanic/in/dev/2021/06/16/\n",
      "projects/project002/01_titanic_model_clas/inference/4/ds01_titanic/out/bronze/dev/\n",
      "projects/project002/01_titanic_model_clas/inference/4/ds01_titanic/out/silver/dev/\n",
      "projects/project002/01_titanic_model_clas/inference/4/ds01_titanic/in/dev/2021/06/16/\n",
      " \n",
      "\n",
      "Training GOLD (p.GoldPath)\n",
      "projects/project002/01_titanic_model_clas/inference/4/gold/dev/\n",
      " \n",
      "\n",
      "[A) USAGE]: to_score_folder, scored_folder, date_folder = p.get_gold_scored_unique_path()\n",
      "A)INFERENCE ONLINE: GOLD to score (example if realtime - today)\n",
      "projects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_17/5704948070bb4c628c6d767376deaf56/\n",
      " \n",
      "\n",
      "A)INFERENCE ONLINE: GOLD scored (example if realtime today)\n",
      "projects/project002/01_titanic_model_clas/inference/4/scored/dev/2021_06_17/5704948070bb4c628c6d767376deaf56/\n",
      " \n",
      "\n",
      "[B) USAGE]: to_score_folder_batch, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder)\n",
      "B)INFERENCE BATCH: GOLD to score (example batch, datetime from config)\n",
      "projects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/c9e0c18ad2c14bcb94cb8973670599e0/\n",
      " \n",
      "\n",
      "B)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\n",
      "projects/project002/01_titanic_model_clas/inference/4/scored/dev/2021_06_16/c9e0c18ad2c14bcb94cb8973670599e0/\n",
      " \n",
      "\n",
      "C) INFERENCE BATCH (SCENARIO 2): TODAY I scored data from X days AGO  (second datefolder from config - X days ago)\n",
      "projects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/c9e0c18ad2c14bcb94cb8973670599e0/2021_06_16/\n",
      "projects/project002/01_titanic_model_clas/inference/4/scored/dev/2021_06_16/c9e0c18ad2c14bcb94cb8973670599e0/2021_06_16/\n",
      " \n",
      "\n",
      "ENVIRONMENT - DEV, TEST, or PROD?  [USAGE: p.dev_test_prod]\n",
      "ACTIVE ENVIRONMENT = dev\n",
      "ACTIVE subscription = ca0a8c40-b06a-4e4e-8434-63c03a1dee34\n",
      "- MSFT-WEU-EAP_PROJECT02_AI-DEV-RG\n",
      "- msft-weu-DEV-eap-proj02_ai-amls\n",
      "- westeurope\n",
      "- MSFT-WEU-EAP_CMN_AI-DEV-RG\n",
      "Active vNet: msft-weu-dev-cmnai-vnet\n",
      "Active SubNet: \n",
      "[USAGE] for the above: p.vNetForActiveEnvironment()\n",
      "Active Lake (storage account)  msftweudevcmnai2\n",
      "[USAGE] for the above: p.getLakeForActiveEnvironment()\n",
      "AML for docker: True\n"
     ]
    }
   ],
   "source": [
    "p = ESMLProject(param_esml_env,param_inference_model_version,param_scoring_folder_date,param_train_in_folder_date)\n",
    "p.ws = p.get_workspace_from_config()\n",
    "p.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "B)INFERENCE BATCH - LATEST scoring that day\nprojects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/gold_to_score.parquet\n"
     ]
    }
   ],
   "source": [
    "print(\"B)INFERENCE BATCH - LATEST scoring that day\")\n",
    "print(p.GoldPathToScoreBatch + 'gold_to_score.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "my_unique_folder_customerID = uuid.uuid4().hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "to_score:  projects/project002/01_titanic_model_clas/inference/4/gold/dev/2021_06_16/fee9f4ebf405423c80a9d1377399f821/gold_to_score.parquet\nsave_scored:  projects/project002/01_titanic_model_clas/inference/4/scored/dev/2021_06_16/fee9f4ebf405423c80a9d1377399f821/scored_caller_id.parquet\n"
     ]
    }
   ],
   "source": [
    "to_score_folder_batch, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder, my_unique_folder_customerID)\n",
    "print(\"to_score: \", to_score_folder_batch + 'gold_to_score.parquet' )\n",
    "print(\"save_scored: \", scored_folder + 'scored_caller_id.parquet' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('project002', 'projects/project002/01_titanic_model_clas/inference/4/scored/dev/2021_06_16/af142621005247d4b9384f3da652e21e/*.parquet')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ReadParquetFile\",\n",
       "    \"DropColumns\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"6b5c76bf-4e31-43d5-bf43-51313e66d76d\",\n",
       "    \"name\": \"M01_GOLD_SCORED\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"Scored gold data with model version 4\",\n",
       "    \"tags\": {\n",
       "      \"date_time_folder\": \"2021_06_16\",\n",
       "      \"caller_id\": \"caller_id\",\n",
       "      \"model_version\": \"4\",\n",
       "      \"model\": \"01_titanic_model_clas\"\n",
       "    },\n",
       "    \"workspace\": \"Workspace.create(name='msft-weu-DEV-eap-proj02_ai-amls', subscription_id='ca0a8c40-b06a-4e4e-8434-63c03a1dee34', resource_group='MSFT-WEU-EAP_PROJECT02_AI-DEV-RG')\"\n",
       "  }\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "from azureml.core.dataset import Dataset \r\n",
    "ds_to_score1 = Dataset.get_by_name(workspace = p.ws, name =  \"M01_GOLD_TO_SCORE\") # Opton 1) Azure ML Dataset directly\r\n",
    "ds_scored = Dataset.get_by_name(workspace = p.ws, name =  \"M01_GOLD_SCORED\") # Opton 2) This would be static for this model, always same, fetches latest version\r\n",
    "ds_scored\r\n"
   ]
  },
  {
   "source": [
    "# 2) WriteBack PIPELINE (remote CPU cluster)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "source": [
    "# EXTRA - more about `AutoLake Paths`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import repackage\n",
    "repackage.add(\"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "p = ESMLProject() \n",
    "p.ws = p.get_workspace_from_config() #2) Load DEV or TEST or PROD Azure ML Studio workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ds01_titanic\nIN projects/project002/01_titanic_model_clas/inference/1/ds01_titanic/in/dev/2021/01/01/\nBronze projects/project002/01_titanic_model_clas/inference/1/ds01_titanic/out/bronze/dev/\nSilver projects/project002/01_titanic_model_clas/inference/1/ds01_titanic/out/silver/dev/\nGold projects/project002/01_titanic_model_clas/inference/1/gold/dev/2021_01_01/0a2b95ef81fe4f57b0ee4f7eb23c2080/   ...uuid folder, is to be able to have multiple unique scorings, same datetime\n\nGold (latest that day) projects/project002/01_titanic_model_clas/inference/1/gold/dev/2021_06_16/  ...No uuid folder, most recent scoring that day\n\nTRAIN\n\nds01_titanic\nIN projects/project002/01_titanic_model_clas/train/ds01_titanic/in/dev/2021/01/01/\nBronze projects/project002/01_titanic_model_clas/train/ds01_titanic/out/bronze/dev/\nSilver projects/project002/01_titanic_model_clas/train/ds01_titanic/out/silver/dev/\nGold projects/project002/01_titanic_model_clas/train/gold/dev/\n"
     ]
    }
   ],
   "source": [
    "p.inference_mode = True # This flag will \"change the paths\", from TRAIN folder to INFERENCE folder-structure\n",
    "\n",
    "for d in p.Datasets:\n",
    "    print(d.Name)\n",
    "    print(\"IN\", d.InPath)\n",
    "    print(\"Bronze\", d.BronzePath)\n",
    "    print(\"Silver\", d.SilverPath)\n",
    "\n",
    "to_score_folder, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder)\n",
    "print(\"Gold\", to_score_folder, \"  ...uuid folder, is to be able to have multiple unique scorings, same datetime\")\n",
    "\n",
    "to_score_folder_latest, scored_folder_latest, date_folder_latest = p.get_gold_scored_unique_path(batch_datetime_from_config = None, unique_uuid4 = None, same_guid_folder=False)\n",
    "print()\n",
    "print(\"Gold (latest that day)\", to_score_folder_latest, \" ...No uuid folder, most recent scoring that day\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"TRAIN\")\n",
    "print(\"\")\n",
    "\n",
    "p.inference_mode = False # This flag will \"change the paths\"\n",
    "\n",
    "for d in p.Datasets:\n",
    "    print(d.Name)\n",
    "    print(\"IN\", d.InPath)\n",
    "    print(\"Bronze\", d.BronzePath)\n",
    "    print(\"Silver\", d.SilverPath)\n",
    "\n",
    "print(\"Gold\", p.GoldPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FLEXIBILITY: If BATCH scoring (date_folder is read from config) && only 'LATEST SCORING that day' is of interest:\n- BUILD your SCORING & WriteBack pipeline, as per your liking (if you don't want support for multiple scorings per day)\n- Note: You need to register your own Azure ML Datasets, if not using the ESML pipeline Scoring&Writeback piplines.\n\n - Date folder only (no guid):\nGold to score (latest that day) projects/project002/01_titanic_model_clas/inference/1/gold/dev/2021_02_02/\n\n - Guidfolder, but static\nGold to score (static GUID folder that day) projects/project002/01_titanic_model_clas/inference/1/gold/dev/2021_02_02/e2fa50410ca343d8a620e55bce4fb244/\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"FLEXIBILITY: If BATCH scoring (date_folder is read from config) && only 'LATEST SCORING that day' is of interest:\")\n",
    "print(\"- BUILD your SCORING & WriteBack pipeline, as per your liking (if you don't want support for multiple scorings per day)\")\n",
    "print(\"- Note: You need to register your own Azure ML Datasets, if not using the ESML pipeline Scoring&Writeback piplines.\")\n",
    "print()\n",
    "\n",
    "print(\" - Date folder only (no guid):\")\n",
    "dt_str = \"2021-02-02 15:35:01.243860\"\n",
    "batch_datetime_from_config = datetime.datetime.strptime(dt_str, '%Y-%m-%d %H:%M:%S.%f') # DateTime\n",
    "to_score_folder_latest, scored_folder_latest, date_folder_latest = p.get_gold_scored_unique_path(batch_datetime_from_config, None,False)\n",
    "print(\"Gold to score (latest that day)\", to_score_folder_latest)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\" - Guidfolder, but static\")\n",
    "guid_folder = 'e2fa50410ca343d8a620e55bce4fb244'\n",
    "to_score_folder_latest, scored_folder_latest, date_folder_latest = p.get_gold_scored_unique_path(batch_datetime_from_config, guid_folder)\n",
    "print(\"Gold to score (static GUID folder that day)\", to_score_folder_latest)"
   ]
  },
  {
   "source": [
    "# More info - How to write ANY file to ADLS gen2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p.LakeAccess.upload(local_file_name, srs_folder, target_path, overwrite=True,use_dataset_factory = False) # BLOB or GEN 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "interpreter": {
   "hash": "3fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}