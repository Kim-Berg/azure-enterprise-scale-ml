import os
import joblib
import sys
import numpy as np
import pandas as pd
import json
import logging

from inference_schema.schema_decorators import input_schema, output_schema
from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType
from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType

output_sample = np.array([0])

# TODO 4 YOU: If you want to use the decorator, @input_schema, You need to speficy YOUR SCHEMA here
#input_sample = pd.DataFrame({"Pclass": pd.Series([0], dtype="int64"), "Name": pd.Series(["example_value"], dtype="object"), "Sex": pd.Series(["example_value"], dtype="object"), "Age": pd.Series([0.0], dtype="float64"), "Siblings/Spouses Aboard": pd.Series([0], dtype="int64"), "Parents/Children Aboard": pd.Series([0], dtype="int64"), "Fare": pd.Series([0.0], dtype="float64")})
input_sample = pd.DataFrame({"AGE": pd.Series([0.0], dtype="float64"), "SEX": pd.Series([0.0], dtype="float64"), "BMI": pd.Series([0.0], dtype="float64"), "BP": pd.Series([0.0], dtype="float64"), "S1": pd.Series([0.0], dtype="float64"), "S2": pd.Series([0.0], dtype="float64"), "S3": pd.Series([0.0], dtype="float64"), "S4": pd.Series([0.0], dtype="float64"), "S5": pd.Series([0.0], dtype="float64"), "S6": pd.Series([0.0], dtype="float64")})

def init():
    global model, info_message
    info_message = ""
    model = None
    
    #print("This file is copied to the Pipeline run train steps 'outputs/your_scoring_file_v_1_0_0.py', by ESML")
    #print("-TODO 4 YOU: Since not using AutoML, which autogenerated the scoring files such as this file - you need to implement this method: init()")
    #print("-Note: This file is only needed, for AKS online deploymet. Not needed for Azure ML pipeline batch scoring")
     
    # EXAMPLE: This name is model.id of model that we want to deploy deserialize the model file back into a sklearn model
    model_name = None
    try:
        model_name = 'model.pkl' # expected to use default name, same as, IESMLController.get_known_model_name_pkl()
        info_message = info_message + "01:Trying to deserialize model with name with {}. ".format(model_name)
        model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), model_name)
        model = joblib.load(model_path)
        info_message = info_message + "01=SUCCESS"
        
        # Logging
        print (info_message)
        logging.info(info_message)
    except Exception as e:
        model_name = '11_diabetes_model_reg'
        info_message = info_message + "02: Could not deserialize model with IESMLController.get_known_model_name_pkl(), usually 'model.pkl', now using custom name: '{}'.".format(model_name)
        try:
            model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), model_name)
            model = joblib.load(model_path)
            info_message = info_message + "02:SUCCESS"
            logging.info(info_message)
        except Exception as e2:
            info_message = info_message + str(e) + str(e2)
            print (info_message)
            logging.error(info_message)

@input_schema('data', PandasParameterType(input_sample))
@output_schema(NumpyParameterType(output_sample))
def run(data):
    #print("This file is copied to the Pipeline run train steps 'outputs/your_scoring_file_v_1_0_0.py', by ESML")
    #print("-TODO 4 YOU: Since not using AutoML, which autogenerated the scoring files such as this file - you need to implement this method: run(data)")
    #print("-Note: This file is only needed, for AKS online deploymet. Not needed for Azure ML pipeline batch scoring")

    if (model is None):
        print (info_message)
        logging.error(info_message)
        return json.dumps({"error": info_message})
    else:
        try:
            probability_y = None
            result = model.predict(data)

            # ADD predict_proba - IF model supports this....need to handle that case
            if model is not None and hasattr(model, 'predict_proba') \
                    and model.predict_proba is not None and data is not None:
                try:
                    probability_y = model.predict_proba(data)
                except Exception as ex:
                    raise ValueError("Model does not support predict_proba method for given dataset \
                        type, inner error: {}".format(ex))
                try:
                    probability_y = convert_to_list(probability_y[:, 1]) # Change to "probability_y" if both [negative_percentage, positive_percentage]
                except Exception as ex:
                    raise ValueError("Model predict_proba output of unsupported type, inner error: {}".format(ex))
            # predict_proba END

            return json.dumps({'result': result.tolist(), 'probability': probability_y,'info': info_message})
        except Exception as e:
            result = str(e) + info_message
            logging.error(info_message)
            return json.dumps({"error": result})

from scipy.sparse import issparse
def convert_to_list(df_series_or_ndarray):
    if issparse(df_series_or_ndarray):
        return df_series_or_ndarray.toarray().tolist()
    if (isinstance(df_series_or_ndarray, pd.DataFrame)):
        return df_series_or_ndarray.values.tolist()
    if (isinstance(df_series_or_ndarray, pd.Series)):
        return df_series_or_ndarray.values.tolist()
    if (isinstance(df_series_or_ndarray, np.ndarray)):
        return df_series_or_ndarray.tolist()
    return df_series_or_ndarray